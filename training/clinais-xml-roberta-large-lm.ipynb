{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98418b43-333d-40de-b56e-41c45bf024f7",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d4745-0a32-4c26-ac7b-8c9d97d780a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbb09f7-6929-4c4d-986a-4f8335ff5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clinais.train.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb85373-23dd-46b6-8089-7a1540350a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f04bee-f5a1-4787-be29-2961ce4f0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:00<00:00, 531174.22it/s]\n"
     ]
    }
   ],
   "source": [
    "finalresult = []\n",
    "for key in tqdm(data['annotated_entries'].keys()):\n",
    "    ident = data['annotated_entries'][key]['note_id']\n",
    "    res = data['annotated_entries'][key]['note_text']\n",
    "    finalresult.append([ident,res])\n",
    "\n",
    "# finalresult    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e3c000c-831b-4f5d-b06f-3ce31a554658",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clinais.dev.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f8d306-1382-432e-abf9-8df40a1d6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 502051.47it/s]\n"
     ]
    }
   ],
   "source": [
    "finalresultdev = []\n",
    "for key in tqdm(data['annotated_entries'].keys()):\n",
    "    ident = data['annotated_entries'][key]['note_id']\n",
    "    res = data['annotated_entries'][key]['note_text']\n",
    "    finalresultdev.append([ident,res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3df269-b09c-4054-8ea9-7b25ebc9751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13ad753b-b796-4332-b5e2-e2b48f87f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=finalresult,columns=['id','text'])\n",
    "dataset_train = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fab4900-9509-40e9-9f6a-d7334c1f9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=finalresultdev,columns=['id','text'])\n",
    "dataset_val = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f26fb1-34c6-4846-ba09-b9952ccfada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(train=dataset_train,val=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b882d9f-4bfe-480f-b4f5-060a41dcdcd6",
   "metadata": {},
   "source": [
    "# Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a648f87-9723-4a08-8862-138070fddf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd9ef6f-d9fb-4752-a340-7f7bb7f14c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1500c3d7-fe6a-431f-b6f9-171424b19ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01602768898010254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37357d35e58b4312b31e5ae238a67f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01203465461730957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7054d4a8444e718449fa48c0bcbcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True,remove_columns=[\"id\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d85e20-7111-41a4-b8c9-b6034206916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060b8c91-a51b-4a93-9245-d2af835c9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 876'\n",
      "'>>> Review 1 length: 608'\n",
      "'>>> Review 2 length: 724'\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = tokenized_dataset[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f26cd16-3f75-477a-b96a-fcaf455fc198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 781\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 127\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7416d9ac-34e6-45cd-9c47-5ea99a8cf901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 2208'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0181e407-c4f8-4d22-83ce-db9c05b1a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe3f02b-d454-459b-b37d-5f3af6d03b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012366771697998047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817070cc737944728c63410d5e7a8b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012119531631469727,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f9df31cde146d19999580c90393a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3562\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 565\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_dataset.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46773083-a305-4650-a205-f67c2c122f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6492aa3-eb74-4be2-bf87-721a52ce852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> <s><mask> May<mask> de 1997, Luther mujer<mask> 29 años de edad<mask> intervenida<mask> en otro centro<mask> deుకున్నాడు carcinoma de la glán<mask> suprarrenal izquierda clínicamente no thôngnte que se manifestó clínicamente como molestias en el flanco iz<mask>do, poco específicas, en el postpart<mask> inmediato; la<mask><mask> y<mask> viršografía axial computer<mask> abdominales mostraron una masa suprarrenal<mask> de 10 cmts<mask><mask> sólida y con áreas de calcificación y nec<mask>s en su interior, siendo la radiografía de tórax y la gammagrafía ósea'\n",
      "\n",
      "'>>> <mask>s. En los análisis, presentaba ligero aumento de la cortisoluria (284.5 m<mask>gr<mask>/24h.)<mask> de 17-OH-estero<mask> en o<mask> (12.7 mcg./24h.), sin síntomas de hiper<mask>tisolismo sistémico. Se realizó resección completa de la tumoración, con el diagnóstico histológico de carcinoma suprarrenal de 10<mask> 7 x 5 cmts. (215 grs. ആധുനിക পদে<mask>capsul<mask>, aunque con invasión vas<mask>,<mask>s zonas de<mask>rosis y un índice mitótico de <mask>/50'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b702405b-6458-4c6e-a6a0-19d350926b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
    "model_name = modelCheckpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-clinais\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    push_to_hub=True,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646c620b-7d69-40b1-8d25-00aad25efd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(modelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf9fdec2-5360-4ee5-8f9e-6652c821e855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/joheras/xlm-roberta-large-finetuned-clinais into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019489526748657227,
       "initial": 1438,
       "n": 1438,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file pytorch_model.bin",
       "rate": null,
       "total": 2240710265,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a09829fceab496cab7086b54058fa31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 1.40k/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01638317108154297,
       "initial": 3579,
       "n": 3579,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file training_args.bin",
       "rate": null,
       "total": 3579,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dc8a23937c4334982878f2262ec38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file training_args.bin: 100%|##########| 3.50k/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011522531509399414,
       "initial": 5504,
       "n": 5504,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file runs/Mar14_19-14-21_minion/events.out.tfevents.1678817691.minion.3844809.0",
       "rate": null,
       "total": 5504,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a1f4dad41d4e2793e47a42432f1f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Mar14_19-14-21_minion/events.out.tfevents.1678817691.minion.3844809.0: 100%|##########| 5.3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011435270309448242,
       "initial": 5787,
       "n": 5787,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file runs/Mar14_19-14-21_minion/1678817698.489144/events.out.tfevents.1678817698.minion.3844809.1",
       "rate": null,
       "total": 5787,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acf543b014d4c869fa8b541a22be34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Mar14_19-14-21_minion/1678817698.489144/events.out.tfevents.1678817698.minion.3844809.1: 10…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012433290481567383,
       "initial": 4180,
       "n": 4180,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file runs/Mar14_19-12-24_minion/events.out.tfevents.1678817574.minion.3844163.0",
       "rate": null,
       "total": 4180,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be8fc1e0bdc458b91ffcdd958786e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Mar14_19-12-24_minion/events.out.tfevents.1678817574.minion.3844163.0: 100%|##########| 4.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011463642120361328,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file training_args.bin",
       "rate": null,
       "total": 3579,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6b16eadb3845a7a140865366bda21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file training_args.bin:  29%|##8       | 1.00k/3.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011585235595703125,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file runs/Mar14_19-14-21_minion/events.out.tfevents.1678817691.minion.3844809.0",
       "rate": null,
       "total": 5504,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e238334734fc0a8c09830d8fb8a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Mar14_19-14-21_minion/events.out.tfevents.1678817691.minion.3844809.0:  19%|#8        | 1.00k/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01147603988647461,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file runs/Mar14_19-14-21_minion/1678817698.489144/events.out.tfevents.1678817698.minion.3844809.1",
       "rate": null,
       "total": 5787,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e370918099492e9774c4beeb12714e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Mar14_19-14-21_minion/1678817698.489144/events.out.tfevents.1678817698.minion.3844809.1:  18%|…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011419534683227539,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file runs/Mar14_19-12-24_minion/events.out.tfevents.1678817574.minion.3844163.0",
       "rate": null,
       "total": 4180,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb5e686e384a59bbaff85b10e49f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Mar14_19-12-24_minion/events.out.tfevents.1678817574.minion.3844163.0:  24%|##4       | 1.00k/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011458158493041992,
       "initial": 5787,
       "n": 5787,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file runs/Mar14_19-12-24_minion/1678817582.3159/events.out.tfevents.1678817582.minion.3844163.1",
       "rate": null,
       "total": 5787,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67b465bb8d248bca88b4eac62298977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Mar14_19-12-24_minion/1678817582.3159/events.out.tfevents.1678817582.minion.3844163.1: 100%…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011580705642700195,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file runs/Mar14_19-12-24_minion/1678817582.3159/events.out.tfevents.1678817582.minion.3844163.1",
       "rate": null,
       "total": 5787,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcb00082187447096a09040a84e414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Mar14_19-12-24_minion/1678817582.3159/events.out.tfevents.1678817582.minion.3844163.1:  18%|#7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011549234390258789,
       "initial": 16901,
       "n": 16901,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file sentencepiece.bpe.model",
       "rate": null,
       "total": 5069051,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b85a2f894754a268914dc7701b93354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file sentencepiece.bpe.model:   0%|          | 16.5k/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011445283889770508,
       "initial": 16899,
       "n": 16899,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file tokenizer.json",
       "rate": null,
       "total": 17082660,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f42af913a44fc825997e11155af0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file tokenizer.json:   0%|          | 16.5k/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011548042297363281,
       "initial": 311,
       "n": 311,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Download file runs/Mar14_19-14-21_minion/events.out.tfevents.1678818511.minion.3844809.2",
       "rate": null,
       "total": 311,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6936f01464c64ec8a9ff2f52f2e1ae6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file runs/Mar14_19-14-21_minion/events.out.tfevents.1678818511.minion.3844809.2: 100%|##########| 311…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01551198959350586,
       "initial": 311,
       "n": 311,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file runs/Mar14_19-14-21_minion/events.out.tfevents.1678818511.minion.3844809.2",
       "rate": null,
       "total": 311,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5807fc5da11b410abfc59ec98e7363a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file runs/Mar14_19-14-21_minion/events.out.tfevents.1678818511.minion.3844809.2: 100%|##########| 311/31…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015540122985839844,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file sentencepiece.bpe.model",
       "rate": null,
       "total": 5069051,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86206bcb1fc344efb9c1789e42938352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file sentencepiece.bpe.model:   0%|          | 1.00k/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015016555786132812,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file tokenizer.json",
       "rate": null,
       "total": 17082660,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f635ba6a3fb648d48547bddb7b8bc0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file tokenizer.json:   0%|          | 1.00k/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016839265823364258,
       "initial": 1024,
       "n": 1024,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Clean file pytorch_model.bin",
       "rate": null,
       "total": 2240710265,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ab24e76b10422db580cea5d1f64844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47a5ba24-cbcd-453b-bea0-2c0ca3d91862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 04:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoheras\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joheras/CLINAIS/wandb/run-20230315_190313-3fzddyqn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/joheras/huggingface/runs/3fzddyqn\" target=\"_blank\">ethereal-wildflower-110</a></strong> to <a href=\"https://wandb.ai/joheras/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 6.51\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51e3f623-605d-41d1-806d-8ca3c3565362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/home/joheras/.local/lib/python3.10/site-packages/transformers/optimization.py:346: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3562\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1115\n",
      "  Number of trainable parameters = 560142482\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1115' max='1115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1115/1115 22:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.425183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.563900</td>\n",
       "      <td>1.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.563900</td>\n",
       "      <td>1.319149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.360700</td>\n",
       "      <td>1.271571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.360700</td>\n",
       "      <td>1.290314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-large-finetuned-clinais/checkpoint-500\n",
      "Configuration saved in xlm-roberta-large-finetuned-clinais/checkpoint-500/config.json\n",
      "Model weights saved in xlm-roberta-large-finetuned-clinais/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-large-finetuned-clinais/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-large-finetuned-clinais/checkpoint-500/special_tokens_map.json\n",
      "tokenizer config file saved in xlm-roberta-large-finetuned-clinais/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-large-finetuned-clinais/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to xlm-roberta-large-finetuned-clinais/checkpoint-1000\n",
      "Configuration saved in xlm-roberta-large-finetuned-clinais/checkpoint-1000/config.json\n",
      "Model weights saved in xlm-roberta-large-finetuned-clinais/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-large-finetuned-clinais/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-large-finetuned-clinais/checkpoint-1000/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1115, training_loss=1.4299662363368835, metrics={'train_runtime': 1322.8126, 'train_samples_per_second': 13.464, 'train_steps_per_second': 0.843, 'total_flos': 4152843915217920.0, 'train_loss': 1.4299662363368835, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a459535-f049-4e80-b6df-3eb8ea53e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForMaskedLM.forward` and have been ignored: word_ids. If word_ids are not expected by `XLMRobertaForMaskedLM.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 565\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 3.78\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dab37a4b-6ba8-40c2-b570-a57d653ba06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to xlm-roberta-large-finetuned-clinais\n",
      "Configuration saved in xlm-roberta-large-finetuned-clinais/config.json\n",
      "Model weights saved in xlm-roberta-large-finetuned-clinais/pytorch_model.bin\n",
      "tokenizer config file saved in xlm-roberta-large-finetuned-clinais/tokenizer_config.json\n",
      "Special tokens file saved in xlm-roberta-large-finetuned-clinais/special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017911434173583984,
       "initial": 32768,
       "n": 32768,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file pytorch_model.bin",
       "rate": null,
       "total": 2240710265,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83854dd132084c2c8947b88207eac61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/2.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015544652938842773,
       "initial": 6201,
       "n": 6201,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file runs/Mar15_18-57-33_minion/events.out.tfevents.1678903392.minion.4007169.0",
       "rate": null,
       "total": 6201,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68009b3f06584ac9aa628902f8dee909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Mar15_18-57-33_minion/events.out.tfevents.1678903392.minion.4007169.0: 100%|##########| 6.06k…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011192083358764648,
       "initial": 311,
       "n": 311,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file runs/Mar15_18-57-33_minion/events.out.tfevents.1678904733.minion.4007169.2",
       "rate": null,
       "total": 311,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9499ed8c1847248b8ad84d028bcd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Mar15_18-57-33_minion/events.out.tfevents.1678904733.minion.4007169.2: 100%|##########| 311/3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files of refs/heads/main for validity...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/joheras/xlm-roberta-large-finetuned-clinais\n",
      "   884bae2..8f50ea8  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Masked Language Modeling', 'type': 'fill-mask'}}\n",
      "To https://huggingface.co/joheras/xlm-roberta-large-finetuned-clinais\n",
      "   8f50ea8..bd7af55  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/joheras/xlm-roberta-large-finetuned-clinais/commit/8f50ea890af56be91da94cbb42ca4ab312d787e7'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf8a5ce-b3a0-4dd0-9ebc-cc8528a5454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf clinico-xlm-roberta-large-finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0453ef0-4b6a-41be-838d-56328589df33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
