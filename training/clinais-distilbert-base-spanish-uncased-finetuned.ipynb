{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98418b43-333d-40de-b56e-41c45bf024f7",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d4745-0a32-4c26-ac7b-8c9d97d780a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbb09f7-6929-4c4d-986a-4f8335ff5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clinais.train.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb85373-23dd-46b6-8089-7a1540350a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f04bee-f5a1-4787-be29-2961ce4f0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:00<00:00, 8708.93it/s]\n"
     ]
    }
   ],
   "source": [
    "finalresult = []\n",
    "for key in tqdm(data['annotated_entries'].keys()):\n",
    "    ident = data['annotated_entries'][key]['note_id']\n",
    "    res = []\n",
    "    tags = []\n",
    "    gold = data['annotated_entries'][key]['boundary_annotation']['gold']\n",
    "    currentboundary = ''\n",
    "    for g in gold:\n",
    "        res.append(g['span'])\n",
    "        if(g['boundary'] is None):\n",
    "            tags.append('I-'+currentboundary)\n",
    "        else:\n",
    "            currentboundary = g['boundary']\n",
    "            tags.append('B-'+currentboundary)\n",
    "    finalresult.append([ident,res,tags])\n",
    "\n",
    "# finalresult    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ec97e8-5a98-406e-92ae-e53207d7faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "tags = [x[2] for x in finalresult]\n",
    "tags = np.unique(list(itertools.chain(*tags)))\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "for i,tag in enumerate(tags):\n",
    "    id2label[i] = tag\n",
    "    label2id[tag] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e73553-4e23-451e-aa01-cd6c1ea4d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalresult = [[x[0],x[1],[label2id[y] for y in x[2]]] for x in finalresult]\n",
    "#finalresult[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3c000c-831b-4f5d-b06f-3ce31a554658",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clinais.dev.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f8d306-1382-432e-abf9-8df40a1d6642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:00<00:00, 8723.11it/s]\n"
     ]
    }
   ],
   "source": [
    "finalresultdev = []\n",
    "for key in tqdm(data['annotated_entries'].keys()):\n",
    "    ident = data['annotated_entries'][key]['note_id']\n",
    "    res = []\n",
    "    tags = []\n",
    "    gold = data['annotated_entries'][key]['boundary_annotation']['gold']\n",
    "    currentboundary = ''\n",
    "    for g in gold:\n",
    "        res.append(g['span'])\n",
    "        if(g['boundary'] is None):\n",
    "            tags.append('I-'+currentboundary)\n",
    "        else:\n",
    "            currentboundary = g['boundary']\n",
    "            tags.append('B-'+currentboundary)\n",
    "    finalresultdev.append([ident,res,tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeef76b3-23b1-4d9e-99a5-c737291e6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalresultdev = [[x[0],x[1],[label2id[y] for y in x[2]]] for x in finalresultdev]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3df269-b09c-4054-8ea9-7b25ebc9751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ad753b-b796-4332-b5e2-e2b48f87f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=finalresult,columns=['id','tokens','tags'])\n",
    "dataset_train = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fab4900-9509-40e9-9f6a-d7334c1f9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=finalresultdev,columns=['id','tokens','tags'])\n",
    "dataset_val = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f26fb1-34c6-4846-ba09-b9952ccfada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(train=dataset_train,val=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b882d9f-4bfe-480f-b4f5-060a41dcdcd6",
   "metadata": {},
   "source": [
    "# Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a648f87-9723-4a08-8862-138070fddf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fd9ef6f-d9fb-4752-a340-7f7bb7f14c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = \"joheras/distilbert-base-spanish-uncased-finetuned-clinais\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1500c3d7-fe6a-431f-b6f9-171424b19ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81627bc7-d56b-4e52-aaeb-8fb0566ddee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015587329864501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1467ac2e214a869d82fd124be350c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012249946594238281,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4879b1ab2cca424ea5867513268f9ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8809a5b8-e25e-478f-8399-61825f24b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 781\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['id', 'tokens', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 127\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46773083-a305-4650-a205-f67c2c122f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28c1426-2367-41d9-a305-55fa1e7623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67009bec-f535-4155-9e80-aa7faa0af0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b702405b-6458-4c6e-a6a0-19d350926b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joheras/distilbert-base-spanish-uncased-finetuned-clinais were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at joheras/distilbert-base-spanish-uncased-finetuned-clinais and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    modelCheckpoint, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdd829ef-beac-4d3a-972f-813578a8d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joheras/CLINAIS/clinico-finetuned is already a clone of https://huggingface.co/joheras/clinico-finetuned. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/joheras/.local/lib/python3.10/site-packages/transformers/optimization.py:346: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 781\n",
      "  Num Epochs = 300\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2100\n",
      "  Number of trainable parameters = 66349070\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoheras\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joheras/CLINAIS/wandb/run-20230316_080235-r2d6rfgt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/joheras/huggingface/runs/r2d6rfgt\" target=\"_blank\">helpful-vortex-114</a></strong> to <a href=\"https://wandb.ai/joheras/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 40:57, Epoch 300/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.788497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.484107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.538079</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.492437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.404870</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.551686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.283494</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.554192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.160865</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.008318</td>\n",
       "      <td>0.606927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.079469</td>\n",
       "      <td>0.011220</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>0.635048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.005567</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.661510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.031503</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.051111</td>\n",
       "      <td>0.027947</td>\n",
       "      <td>0.650550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.034054</td>\n",
       "      <td>0.029728</td>\n",
       "      <td>0.052222</td>\n",
       "      <td>0.037888</td>\n",
       "      <td>0.661009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934085</td>\n",
       "      <td>0.026384</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>0.690226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.030228</td>\n",
       "      <td>0.067778</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.703410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.887483</td>\n",
       "      <td>0.042216</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.057245</td>\n",
       "      <td>0.710863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.869109</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.097778</td>\n",
       "      <td>0.065549</td>\n",
       "      <td>0.725237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.844203</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.078976</td>\n",
       "      <td>0.740331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.807671</td>\n",
       "      <td>0.067560</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>0.750791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.790075</td>\n",
       "      <td>0.070075</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.092389</td>\n",
       "      <td>0.754768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.778030</td>\n",
       "      <td>0.073780</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>0.756991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.762288</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.157778</td>\n",
       "      <td>0.110377</td>\n",
       "      <td>0.761970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.749513</td>\n",
       "      <td>0.100292</td>\n",
       "      <td>0.191111</td>\n",
       "      <td>0.131549</td>\n",
       "      <td>0.768202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748842</td>\n",
       "      <td>0.099506</td>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.127879</td>\n",
       "      <td>0.774309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.738321</td>\n",
       "      <td>0.103751</td>\n",
       "      <td>0.196667</td>\n",
       "      <td>0.135840</td>\n",
       "      <td>0.775561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721236</td>\n",
       "      <td>0.122089</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>0.155886</td>\n",
       "      <td>0.783140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721275</td>\n",
       "      <td>0.112139</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>0.147529</td>\n",
       "      <td>0.778943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721964</td>\n",
       "      <td>0.119520</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.155166</td>\n",
       "      <td>0.781386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.728547</td>\n",
       "      <td>0.121937</td>\n",
       "      <td>0.226667</td>\n",
       "      <td>0.158570</td>\n",
       "      <td>0.781292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709235</td>\n",
       "      <td>0.130692</td>\n",
       "      <td>0.245556</td>\n",
       "      <td>0.170591</td>\n",
       "      <td>0.784236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697876</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.154924</td>\n",
       "      <td>0.784987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.699235</td>\n",
       "      <td>0.151665</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.195083</td>\n",
       "      <td>0.785332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694412</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.252222</td>\n",
       "      <td>0.177136</td>\n",
       "      <td>0.787305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709802</td>\n",
       "      <td>0.145808</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.188531</td>\n",
       "      <td>0.788620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682883</td>\n",
       "      <td>0.153661</td>\n",
       "      <td>0.284444</td>\n",
       "      <td>0.199532</td>\n",
       "      <td>0.790060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.169643</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.220930</td>\n",
       "      <td>0.793129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.733793</td>\n",
       "      <td>0.142351</td>\n",
       "      <td>0.267778</td>\n",
       "      <td>0.185885</td>\n",
       "      <td>0.781480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698759</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.205950</td>\n",
       "      <td>0.791720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.706161</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.325556</td>\n",
       "      <td>0.220467</td>\n",
       "      <td>0.791470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700447</td>\n",
       "      <td>0.167416</td>\n",
       "      <td>0.331111</td>\n",
       "      <td>0.222388</td>\n",
       "      <td>0.798046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700219</td>\n",
       "      <td>0.163231</td>\n",
       "      <td>0.325556</td>\n",
       "      <td>0.217440</td>\n",
       "      <td>0.796167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.728419</td>\n",
       "      <td>0.173611</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0.797263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.715982</td>\n",
       "      <td>0.182763</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0.235804</td>\n",
       "      <td>0.800990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.180987</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.791877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702969</td>\n",
       "      <td>0.174719</td>\n",
       "      <td>0.345556</td>\n",
       "      <td>0.232090</td>\n",
       "      <td>0.797482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721142</td>\n",
       "      <td>0.184018</td>\n",
       "      <td>0.363333</td>\n",
       "      <td>0.244303</td>\n",
       "      <td>0.798547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.740001</td>\n",
       "      <td>0.196528</td>\n",
       "      <td>0.352222</td>\n",
       "      <td>0.252288</td>\n",
       "      <td>0.798860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682103</td>\n",
       "      <td>0.192584</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.250389</td>\n",
       "      <td>0.807221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693273</td>\n",
       "      <td>0.201084</td>\n",
       "      <td>0.371111</td>\n",
       "      <td>0.260836</td>\n",
       "      <td>0.804528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692373</td>\n",
       "      <td>0.204573</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.265418</td>\n",
       "      <td>0.807628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.690371</td>\n",
       "      <td>0.192547</td>\n",
       "      <td>0.378889</td>\n",
       "      <td>0.255335</td>\n",
       "      <td>0.808818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.704857</td>\n",
       "      <td>0.209726</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.271120</td>\n",
       "      <td>0.808537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708206</td>\n",
       "      <td>0.207885</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.270396</td>\n",
       "      <td>0.810885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710187</td>\n",
       "      <td>0.211144</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.276392</td>\n",
       "      <td>0.808067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.737350</td>\n",
       "      <td>0.194906</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>0.802869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.720852</td>\n",
       "      <td>0.209913</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.275335</td>\n",
       "      <td>0.809100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.749813</td>\n",
       "      <td>0.223636</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.289412</td>\n",
       "      <td>0.806438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721163</td>\n",
       "      <td>0.226529</td>\n",
       "      <td>0.415556</td>\n",
       "      <td>0.293218</td>\n",
       "      <td>0.811699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721147</td>\n",
       "      <td>0.215990</td>\n",
       "      <td>0.402222</td>\n",
       "      <td>0.281056</td>\n",
       "      <td>0.809570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.729783</td>\n",
       "      <td>0.211155</td>\n",
       "      <td>0.412222</td>\n",
       "      <td>0.279262</td>\n",
       "      <td>0.807566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.736176</td>\n",
       "      <td>0.228834</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.294862</td>\n",
       "      <td>0.809789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.737617</td>\n",
       "      <td>0.228739</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.299424</td>\n",
       "      <td>0.811449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.738267</td>\n",
       "      <td>0.225209</td>\n",
       "      <td>0.418889</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.810948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744485</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.293669</td>\n",
       "      <td>0.812388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.745958</td>\n",
       "      <td>0.236891</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.304641</td>\n",
       "      <td>0.812576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.773467</td>\n",
       "      <td>0.215777</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.283537</td>\n",
       "      <td>0.805342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.754276</td>\n",
       "      <td>0.235117</td>\n",
       "      <td>0.434444</td>\n",
       "      <td>0.305111</td>\n",
       "      <td>0.811512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.760816</td>\n",
       "      <td>0.224797</td>\n",
       "      <td>0.431111</td>\n",
       "      <td>0.295506</td>\n",
       "      <td>0.804591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.771706</td>\n",
       "      <td>0.238537</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.313382</td>\n",
       "      <td>0.810353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.781204</td>\n",
       "      <td>0.235739</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.309396</td>\n",
       "      <td>0.809507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.759088</td>\n",
       "      <td>0.243757</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.317583</td>\n",
       "      <td>0.814048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.769990</td>\n",
       "      <td>0.239763</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>0.312573</td>\n",
       "      <td>0.812169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.765419</td>\n",
       "      <td>0.255465</td>\n",
       "      <td>0.454444</td>\n",
       "      <td>0.327069</td>\n",
       "      <td>0.814925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.780389</td>\n",
       "      <td>0.234844</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>0.307041</td>\n",
       "      <td>0.810259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.771711</td>\n",
       "      <td>0.251664</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.325891</td>\n",
       "      <td>0.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.796137</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.315956</td>\n",
       "      <td>0.813391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.788866</td>\n",
       "      <td>0.241236</td>\n",
       "      <td>0.451111</td>\n",
       "      <td>0.314363</td>\n",
       "      <td>0.814862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.786945</td>\n",
       "      <td>0.248626</td>\n",
       "      <td>0.452222</td>\n",
       "      <td>0.320851</td>\n",
       "      <td>0.814549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.815868</td>\n",
       "      <td>0.226062</td>\n",
       "      <td>0.443333</td>\n",
       "      <td>0.299437</td>\n",
       "      <td>0.808067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.818664</td>\n",
       "      <td>0.240396</td>\n",
       "      <td>0.458889</td>\n",
       "      <td>0.315508</td>\n",
       "      <td>0.810228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.828558</td>\n",
       "      <td>0.237734</td>\n",
       "      <td>0.452222</td>\n",
       "      <td>0.311639</td>\n",
       "      <td>0.809664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.825021</td>\n",
       "      <td>0.245593</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>0.317485</td>\n",
       "      <td>0.810917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.812414</td>\n",
       "      <td>0.235574</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.306858</td>\n",
       "      <td>0.811512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.825917</td>\n",
       "      <td>0.240476</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>0.313178</td>\n",
       "      <td>0.811793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.836111</td>\n",
       "      <td>0.244848</td>\n",
       "      <td>0.448889</td>\n",
       "      <td>0.316863</td>\n",
       "      <td>0.810948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.836324</td>\n",
       "      <td>0.242461</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.314308</td>\n",
       "      <td>0.810823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.812944</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.454444</td>\n",
       "      <td>0.320031</td>\n",
       "      <td>0.814549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.811734</td>\n",
       "      <td>0.256442</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.327579</td>\n",
       "      <td>0.815395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.821817</td>\n",
       "      <td>0.252734</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.326787</td>\n",
       "      <td>0.814643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.824155</td>\n",
       "      <td>0.253027</td>\n",
       "      <td>0.464444</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.814487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.250302</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.324197</td>\n",
       "      <td>0.813547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.825577</td>\n",
       "      <td>0.248645</td>\n",
       "      <td>0.458889</td>\n",
       "      <td>0.322530</td>\n",
       "      <td>0.814424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.829349</td>\n",
       "      <td>0.243787</td>\n",
       "      <td>0.457778</td>\n",
       "      <td>0.318147</td>\n",
       "      <td>0.813578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.809342</td>\n",
       "      <td>0.248524</td>\n",
       "      <td>0.467778</td>\n",
       "      <td>0.324595</td>\n",
       "      <td>0.819497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.826657</td>\n",
       "      <td>0.254456</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.327661</td>\n",
       "      <td>0.815301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.833102</td>\n",
       "      <td>0.254310</td>\n",
       "      <td>0.458889</td>\n",
       "      <td>0.327258</td>\n",
       "      <td>0.817712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.839676</td>\n",
       "      <td>0.256898</td>\n",
       "      <td>0.465556</td>\n",
       "      <td>0.331094</td>\n",
       "      <td>0.815489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.831983</td>\n",
       "      <td>0.255488</td>\n",
       "      <td>0.465556</td>\n",
       "      <td>0.329921</td>\n",
       "      <td>0.816115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.850678</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.318043</td>\n",
       "      <td>0.812357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.869833</td>\n",
       "      <td>0.256379</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.810196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.861025</td>\n",
       "      <td>0.248053</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.322304</td>\n",
       "      <td>0.815395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.857337</td>\n",
       "      <td>0.250458</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.323216</td>\n",
       "      <td>0.811981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.849221</td>\n",
       "      <td>0.265655</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.338573</td>\n",
       "      <td>0.816303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.876532</td>\n",
       "      <td>0.248968</td>\n",
       "      <td>0.468889</td>\n",
       "      <td>0.325241</td>\n",
       "      <td>0.812733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.868231</td>\n",
       "      <td>0.270662</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.345272</td>\n",
       "      <td>0.812357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.870857</td>\n",
       "      <td>0.252675</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.329202</td>\n",
       "      <td>0.815082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>0.266542</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.341327</td>\n",
       "      <td>0.814768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.867502</td>\n",
       "      <td>0.260949</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.337264</td>\n",
       "      <td>0.815583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.895343</td>\n",
       "      <td>0.259509</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>0.811919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.872069</td>\n",
       "      <td>0.274032</td>\n",
       "      <td>0.487778</td>\n",
       "      <td>0.350919</td>\n",
       "      <td>0.816240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.856981</td>\n",
       "      <td>0.271628</td>\n",
       "      <td>0.474444</td>\n",
       "      <td>0.345469</td>\n",
       "      <td>0.816710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.888087</td>\n",
       "      <td>0.258434</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.335156</td>\n",
       "      <td>0.813672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.885516</td>\n",
       "      <td>0.269278</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.347277</td>\n",
       "      <td>0.816491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.882451</td>\n",
       "      <td>0.253922</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>0.816553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.875543</td>\n",
       "      <td>0.258084</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.335409</td>\n",
       "      <td>0.814017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.884062</td>\n",
       "      <td>0.271869</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.347127</td>\n",
       "      <td>0.815395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.876621</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.346276</td>\n",
       "      <td>0.816491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.885605</td>\n",
       "      <td>0.267934</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.345318</td>\n",
       "      <td>0.817148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.909898</td>\n",
       "      <td>0.271016</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.346431</td>\n",
       "      <td>0.815896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.958771</td>\n",
       "      <td>0.271240</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.809006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.890204</td>\n",
       "      <td>0.274583</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.352801</td>\n",
       "      <td>0.818244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.891658</td>\n",
       "      <td>0.276250</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.817274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.898370</td>\n",
       "      <td>0.285262</td>\n",
       "      <td>0.501111</td>\n",
       "      <td>0.363563</td>\n",
       "      <td>0.817305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.903499</td>\n",
       "      <td>0.281038</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.361254</td>\n",
       "      <td>0.817524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.924929</td>\n",
       "      <td>0.277813</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.353417</td>\n",
       "      <td>0.814549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.914918</td>\n",
       "      <td>0.272841</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.349079</td>\n",
       "      <td>0.815864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.936513</td>\n",
       "      <td>0.268731</td>\n",
       "      <td>0.482222</td>\n",
       "      <td>0.345129</td>\n",
       "      <td>0.812201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.918157</td>\n",
       "      <td>0.276166</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.352373</td>\n",
       "      <td>0.815645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.907919</td>\n",
       "      <td>0.274739</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.353779</td>\n",
       "      <td>0.816491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.915872</td>\n",
       "      <td>0.281366</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.360956</td>\n",
       "      <td>0.819779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.902536</td>\n",
       "      <td>0.268541</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.349145</td>\n",
       "      <td>0.819560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.940089</td>\n",
       "      <td>0.279550</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.357743</td>\n",
       "      <td>0.816303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.939633</td>\n",
       "      <td>0.283215</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.357757</td>\n",
       "      <td>0.817054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.906669</td>\n",
       "      <td>0.278370</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.355912</td>\n",
       "      <td>0.821094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.928793</td>\n",
       "      <td>0.274732</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.350623</td>\n",
       "      <td>0.816585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.928660</td>\n",
       "      <td>0.282874</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.358682</td>\n",
       "      <td>0.817681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.928628</td>\n",
       "      <td>0.280878</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.359118</td>\n",
       "      <td>0.815050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.922309</td>\n",
       "      <td>0.287386</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.362592</td>\n",
       "      <td>0.816240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.922801</td>\n",
       "      <td>0.287602</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.367216</td>\n",
       "      <td>0.819090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.930695</td>\n",
       "      <td>0.282924</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.361078</td>\n",
       "      <td>0.820123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.928113</td>\n",
       "      <td>0.279924</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.356595</td>\n",
       "      <td>0.818307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.930808</td>\n",
       "      <td>0.282147</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.361311</td>\n",
       "      <td>0.819278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.960080</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.364146</td>\n",
       "      <td>0.815990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.959634</td>\n",
       "      <td>0.274497</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.350722</td>\n",
       "      <td>0.815896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.297571</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.370277</td>\n",
       "      <td>0.819466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.945545</td>\n",
       "      <td>0.282948</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>0.819309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.955005</td>\n",
       "      <td>0.284450</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.362611</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.940655</td>\n",
       "      <td>0.287282</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.363414</td>\n",
       "      <td>0.821689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.936127</td>\n",
       "      <td>0.294003</td>\n",
       "      <td>0.501111</td>\n",
       "      <td>0.370583</td>\n",
       "      <td>0.822034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.958197</td>\n",
       "      <td>0.286538</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.363415</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.952165</td>\n",
       "      <td>0.291002</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.369680</td>\n",
       "      <td>0.819622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.947307</td>\n",
       "      <td>0.282776</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.358306</td>\n",
       "      <td>0.818808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.951982</td>\n",
       "      <td>0.288437</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.367017</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.956144</td>\n",
       "      <td>0.281388</td>\n",
       "      <td>0.495556</td>\n",
       "      <td>0.358954</td>\n",
       "      <td>0.819340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.953063</td>\n",
       "      <td>0.285077</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.362237</td>\n",
       "      <td>0.819779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.298429</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.375618</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.940702</td>\n",
       "      <td>0.282878</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.821470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.959760</td>\n",
       "      <td>0.287898</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.365992</td>\n",
       "      <td>0.819372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.980733</td>\n",
       "      <td>0.286912</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.363117</td>\n",
       "      <td>0.816115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.984308</td>\n",
       "      <td>0.279026</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.357314</td>\n",
       "      <td>0.816272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.952635</td>\n",
       "      <td>0.281152</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.359632</td>\n",
       "      <td>0.820311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.948783</td>\n",
       "      <td>0.281957</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.363708</td>\n",
       "      <td>0.820186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.976549</td>\n",
       "      <td>0.283967</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.359560</td>\n",
       "      <td>0.817274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.985305</td>\n",
       "      <td>0.286628</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.363784</td>\n",
       "      <td>0.816710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.969261</td>\n",
       "      <td>0.290013</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.367994</td>\n",
       "      <td>0.818902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.976088</td>\n",
       "      <td>0.278864</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.355734</td>\n",
       "      <td>0.816272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.957733</td>\n",
       "      <td>0.293620</td>\n",
       "      <td>0.501111</td>\n",
       "      <td>0.370279</td>\n",
       "      <td>0.819560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.970710</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.360064</td>\n",
       "      <td>0.819403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.967196</td>\n",
       "      <td>0.288903</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.367099</td>\n",
       "      <td>0.819153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.962805</td>\n",
       "      <td>0.291107</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.369468</td>\n",
       "      <td>0.819779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.980320</td>\n",
       "      <td>0.281231</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.361980</td>\n",
       "      <td>0.819497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.280101</td>\n",
       "      <td>0.491111</td>\n",
       "      <td>0.356739</td>\n",
       "      <td>0.818933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.977843</td>\n",
       "      <td>0.282019</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.359759</td>\n",
       "      <td>0.819215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.967949</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.364294</td>\n",
       "      <td>0.819779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.977955</td>\n",
       "      <td>0.291508</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.371267</td>\n",
       "      <td>0.817587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.965114</td>\n",
       "      <td>0.296415</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.376117</td>\n",
       "      <td>0.821940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.989531</td>\n",
       "      <td>0.283450</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.360920</td>\n",
       "      <td>0.819779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.957876</td>\n",
       "      <td>0.292839</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.371753</td>\n",
       "      <td>0.824664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.988599</td>\n",
       "      <td>0.289032</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>0.818057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.982684</td>\n",
       "      <td>0.285531</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.817430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.283439</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.360324</td>\n",
       "      <td>0.820812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.984957</td>\n",
       "      <td>0.285623</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.362677</td>\n",
       "      <td>0.820029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.999135</td>\n",
       "      <td>0.289750</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.364162</td>\n",
       "      <td>0.816334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.988153</td>\n",
       "      <td>0.292459</td>\n",
       "      <td>0.495556</td>\n",
       "      <td>0.367835</td>\n",
       "      <td>0.819090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.983549</td>\n",
       "      <td>0.297859</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.376075</td>\n",
       "      <td>0.819027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>0.290260</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.366393</td>\n",
       "      <td>0.814487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.990124</td>\n",
       "      <td>0.297386</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.374486</td>\n",
       "      <td>0.816334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.990696</td>\n",
       "      <td>0.294534</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.373116</td>\n",
       "      <td>0.819121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.996518</td>\n",
       "      <td>0.287414</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.367641</td>\n",
       "      <td>0.819904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.001674</td>\n",
       "      <td>0.303654</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.380042</td>\n",
       "      <td>0.819591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.986588</td>\n",
       "      <td>0.297818</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.377543</td>\n",
       "      <td>0.822096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.003924</td>\n",
       "      <td>0.294702</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.369295</td>\n",
       "      <td>0.818057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.988499</td>\n",
       "      <td>0.295324</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.374644</td>\n",
       "      <td>0.820217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.006590</td>\n",
       "      <td>0.287636</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.364892</td>\n",
       "      <td>0.819560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.993797</td>\n",
       "      <td>0.295263</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.372798</td>\n",
       "      <td>0.820938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.994821</td>\n",
       "      <td>0.298942</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.374793</td>\n",
       "      <td>0.820969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.994666</td>\n",
       "      <td>0.300395</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.377171</td>\n",
       "      <td>0.821219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.003655</td>\n",
       "      <td>0.295618</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.372170</td>\n",
       "      <td>0.819403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.022000</td>\n",
       "      <td>0.294847</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.371558</td>\n",
       "      <td>0.815958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.018555</td>\n",
       "      <td>0.296272</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.370525</td>\n",
       "      <td>0.816522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.014806</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.369919</td>\n",
       "      <td>0.821251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.009432</td>\n",
       "      <td>0.294386</td>\n",
       "      <td>0.501111</td>\n",
       "      <td>0.370888</td>\n",
       "      <td>0.818996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.016018</td>\n",
       "      <td>0.290052</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.366830</td>\n",
       "      <td>0.820123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.011187</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.379958</td>\n",
       "      <td>0.818933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.015794</td>\n",
       "      <td>0.296804</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.374024</td>\n",
       "      <td>0.818777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.003512</td>\n",
       "      <td>0.289507</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.369057</td>\n",
       "      <td>0.821282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.010496</td>\n",
       "      <td>0.288832</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.366151</td>\n",
       "      <td>0.818745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.012694</td>\n",
       "      <td>0.293316</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.370340</td>\n",
       "      <td>0.819121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.017592</td>\n",
       "      <td>0.296031</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.373410</td>\n",
       "      <td>0.820155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.018051</td>\n",
       "      <td>0.295114</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.372074</td>\n",
       "      <td>0.818464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.013063</td>\n",
       "      <td>0.303974</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.380913</td>\n",
       "      <td>0.821877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.025647</td>\n",
       "      <td>0.295395</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.371074</td>\n",
       "      <td>0.817430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.006389</td>\n",
       "      <td>0.300463</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.376607</td>\n",
       "      <td>0.821940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.019283</td>\n",
       "      <td>0.291857</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.367967</td>\n",
       "      <td>0.819121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.008497</td>\n",
       "      <td>0.296845</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.375866</td>\n",
       "      <td>0.822096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.013783</td>\n",
       "      <td>0.297735</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.376278</td>\n",
       "      <td>0.820687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.019558</td>\n",
       "      <td>0.296320</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.374847</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.013835</td>\n",
       "      <td>0.306230</td>\n",
       "      <td>0.518889</td>\n",
       "      <td>0.385155</td>\n",
       "      <td>0.820812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.017118</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.376752</td>\n",
       "      <td>0.821689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.024268</td>\n",
       "      <td>0.298942</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.374793</td>\n",
       "      <td>0.818996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.027261</td>\n",
       "      <td>0.299608</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.377467</td>\n",
       "      <td>0.819935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.041905</td>\n",
       "      <td>0.291694</td>\n",
       "      <td>0.495556</td>\n",
       "      <td>0.367229</td>\n",
       "      <td>0.818902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.036121</td>\n",
       "      <td>0.292092</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.371151</td>\n",
       "      <td>0.820812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.035299</td>\n",
       "      <td>0.305858</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.379223</td>\n",
       "      <td>0.817524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.039855</td>\n",
       "      <td>0.290448</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.366544</td>\n",
       "      <td>0.818871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.030028</td>\n",
       "      <td>0.296660</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.817180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.040636</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.367816</td>\n",
       "      <td>0.817180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.039736</td>\n",
       "      <td>0.295885</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.372686</td>\n",
       "      <td>0.815395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.030334</td>\n",
       "      <td>0.291480</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.369768</td>\n",
       "      <td>0.818276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.050261</td>\n",
       "      <td>0.291558</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.368033</td>\n",
       "      <td>0.816366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.030413</td>\n",
       "      <td>0.296753</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.374590</td>\n",
       "      <td>0.819309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.041084</td>\n",
       "      <td>0.302588</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.378895</td>\n",
       "      <td>0.817618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.047581</td>\n",
       "      <td>0.288437</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.367017</td>\n",
       "      <td>0.818057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.056134</td>\n",
       "      <td>0.293962</td>\n",
       "      <td>0.492222</td>\n",
       "      <td>0.368093</td>\n",
       "      <td>0.817086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.039572</td>\n",
       "      <td>0.290862</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.368378</td>\n",
       "      <td>0.817712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.042377</td>\n",
       "      <td>0.291614</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.371059</td>\n",
       "      <td>0.818714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.046985</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.375359</td>\n",
       "      <td>0.819121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.037089</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.376895</td>\n",
       "      <td>0.820562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.031783</td>\n",
       "      <td>0.299674</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.377823</td>\n",
       "      <td>0.821125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.032509</td>\n",
       "      <td>0.294344</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.372964</td>\n",
       "      <td>0.818589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.029993</td>\n",
       "      <td>0.297228</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.376173</td>\n",
       "      <td>0.819372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.040919</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.372565</td>\n",
       "      <td>0.818620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.038457</td>\n",
       "      <td>0.294042</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.373019</td>\n",
       "      <td>0.818057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.045206</td>\n",
       "      <td>0.296463</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.375560</td>\n",
       "      <td>0.818558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.048017</td>\n",
       "      <td>0.299676</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.378732</td>\n",
       "      <td>0.819434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.040282</td>\n",
       "      <td>0.293548</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.819309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.035689</td>\n",
       "      <td>0.300713</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.379861</td>\n",
       "      <td>0.820938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.050064</td>\n",
       "      <td>0.291059</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.370610</td>\n",
       "      <td>0.818213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.051647</td>\n",
       "      <td>0.295425</td>\n",
       "      <td>0.502222</td>\n",
       "      <td>0.372016</td>\n",
       "      <td>0.818151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.031528</td>\n",
       "      <td>0.304147</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.381976</td>\n",
       "      <td>0.820343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.045179</td>\n",
       "      <td>0.295885</td>\n",
       "      <td>0.503333</td>\n",
       "      <td>0.372686</td>\n",
       "      <td>0.818401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.048517</td>\n",
       "      <td>0.295071</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.372645</td>\n",
       "      <td>0.818683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.037967</td>\n",
       "      <td>0.297749</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.377189</td>\n",
       "      <td>0.820499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.042016</td>\n",
       "      <td>0.293928</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.371732</td>\n",
       "      <td>0.819528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.048887</td>\n",
       "      <td>0.296610</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.373870</td>\n",
       "      <td>0.819247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.041987</td>\n",
       "      <td>0.298440</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.376538</td>\n",
       "      <td>0.819340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.053843</td>\n",
       "      <td>0.288190</td>\n",
       "      <td>0.498889</td>\n",
       "      <td>0.365338</td>\n",
       "      <td>0.816084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.048698</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.375359</td>\n",
       "      <td>0.820029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.046107</td>\n",
       "      <td>0.299476</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.376752</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.051939</td>\n",
       "      <td>0.292495</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.370882</td>\n",
       "      <td>0.819340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.062510</td>\n",
       "      <td>0.286628</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.363784</td>\n",
       "      <td>0.816961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.046932</td>\n",
       "      <td>0.294614</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.371979</td>\n",
       "      <td>0.817368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.049716</td>\n",
       "      <td>0.294269</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.372605</td>\n",
       "      <td>0.820155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.058441</td>\n",
       "      <td>0.293436</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.371638</td>\n",
       "      <td>0.818432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.053954</td>\n",
       "      <td>0.294695</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.370828</td>\n",
       "      <td>0.818652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.045384</td>\n",
       "      <td>0.297914</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.375514</td>\n",
       "      <td>0.820092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.044431</td>\n",
       "      <td>0.300130</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.378489</td>\n",
       "      <td>0.820092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.050624</td>\n",
       "      <td>0.289809</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.820875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.049357</td>\n",
       "      <td>0.295189</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.372436</td>\n",
       "      <td>0.821501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.040556</td>\n",
       "      <td>0.297158</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.375817</td>\n",
       "      <td>0.822253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.053940</td>\n",
       "      <td>0.295765</td>\n",
       "      <td>0.504444</td>\n",
       "      <td>0.372895</td>\n",
       "      <td>0.819748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.058302</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.375510</td>\n",
       "      <td>0.819967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.056714</td>\n",
       "      <td>0.300196</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.377933</td>\n",
       "      <td>0.819685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.056586</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.379778</td>\n",
       "      <td>0.818996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.060437</td>\n",
       "      <td>0.299162</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.378621</td>\n",
       "      <td>0.818683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.059277</td>\n",
       "      <td>0.296583</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.375357</td>\n",
       "      <td>0.818307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.056617</td>\n",
       "      <td>0.301702</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.379736</td>\n",
       "      <td>0.819372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.057486</td>\n",
       "      <td>0.302477</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.381265</td>\n",
       "      <td>0.820155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.055337</td>\n",
       "      <td>0.300064</td>\n",
       "      <td>0.521111</td>\n",
       "      <td>0.380836</td>\n",
       "      <td>0.821094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.054591</td>\n",
       "      <td>0.297489</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.376682</td>\n",
       "      <td>0.820844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.049798</td>\n",
       "      <td>0.300130</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.378489</td>\n",
       "      <td>0.821564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.050231</td>\n",
       "      <td>0.301236</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.379975</td>\n",
       "      <td>0.821251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.050388</td>\n",
       "      <td>0.301494</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.380484</td>\n",
       "      <td>0.821125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.051680</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.375359</td>\n",
       "      <td>0.820750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.049545</td>\n",
       "      <td>0.301567</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.379934</td>\n",
       "      <td>0.821188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.051860</td>\n",
       "      <td>0.296556</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.376823</td>\n",
       "      <td>0.820530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.052775</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.375457</td>\n",
       "      <td>0.820656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.052304</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.820217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>1.049853</td>\n",
       "      <td>0.299542</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.377110</td>\n",
       "      <td>0.820530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.048055</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.376384</td>\n",
       "      <td>0.820781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.048418</td>\n",
       "      <td>0.302417</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.380913</td>\n",
       "      <td>0.821219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.049749</td>\n",
       "      <td>0.300582</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.380057</td>\n",
       "      <td>0.821345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.050094</td>\n",
       "      <td>0.299935</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.379240</td>\n",
       "      <td>0.820969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.052021</td>\n",
       "      <td>0.300457</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.055313</td>\n",
       "      <td>0.298761</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.376490</td>\n",
       "      <td>0.820562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.056730</td>\n",
       "      <td>0.299935</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.378334</td>\n",
       "      <td>0.820718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.054911</td>\n",
       "      <td>0.301244</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.379069</td>\n",
       "      <td>0.820844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.052502</td>\n",
       "      <td>0.296985</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.376576</td>\n",
       "      <td>0.820499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.375305</td>\n",
       "      <td>0.820562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.053287</td>\n",
       "      <td>0.300195</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.378844</td>\n",
       "      <td>0.820562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.053728</td>\n",
       "      <td>0.301702</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.379736</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.053822</td>\n",
       "      <td>0.299608</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.377467</td>\n",
       "      <td>0.820405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.053697</td>\n",
       "      <td>0.300786</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.378401</td>\n",
       "      <td>0.820530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.053585</td>\n",
       "      <td>0.300393</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.378089</td>\n",
       "      <td>0.820437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-7\n",
      "Configuration saved in clinico-finetuned/checkpoint-7/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-7/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-7/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-7/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-14\n",
      "Configuration saved in clinico-finetuned/checkpoint-14/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-14/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-14/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-14/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-21\n",
      "Configuration saved in clinico-finetuned/checkpoint-21/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-21/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-21/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-21/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-28\n",
      "Configuration saved in clinico-finetuned/checkpoint-28/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-28/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-28/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-28/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-35\n",
      "Configuration saved in clinico-finetuned/checkpoint-35/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-35/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-35/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-35/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-42\n",
      "Configuration saved in clinico-finetuned/checkpoint-42/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-42/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-42/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-42/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-49\n",
      "Configuration saved in clinico-finetuned/checkpoint-49/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-49/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-49/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-49/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-56\n",
      "Configuration saved in clinico-finetuned/checkpoint-56/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-56/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-56/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-56/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-63\n",
      "Configuration saved in clinico-finetuned/checkpoint-63/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-63/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-63/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-63/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-70\n",
      "Configuration saved in clinico-finetuned/checkpoint-70/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-70/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-77\n",
      "Configuration saved in clinico-finetuned/checkpoint-77/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-77/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-77/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-77/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-84\n",
      "Configuration saved in clinico-finetuned/checkpoint-84/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-84/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-84/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-84/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-91\n",
      "Configuration saved in clinico-finetuned/checkpoint-91/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-91/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-91/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-91/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-98\n",
      "Configuration saved in clinico-finetuned/checkpoint-98/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-98/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-98/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-98/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-105\n",
      "Configuration saved in clinico-finetuned/checkpoint-105/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-105/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-105/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-105/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-112\n",
      "Configuration saved in clinico-finetuned/checkpoint-112/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-112/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-112/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-112/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-119\n",
      "Configuration saved in clinico-finetuned/checkpoint-119/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-119/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-119/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-119/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-126\n",
      "Configuration saved in clinico-finetuned/checkpoint-126/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-126/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-126/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-126/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-133\n",
      "Configuration saved in clinico-finetuned/checkpoint-133/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-133/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-133/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-133/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-140\n",
      "Configuration saved in clinico-finetuned/checkpoint-140/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-140/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-140/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-140/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-147\n",
      "Configuration saved in clinico-finetuned/checkpoint-147/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-147/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-147/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-147/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-154\n",
      "Configuration saved in clinico-finetuned/checkpoint-154/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-154/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-154/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-154/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-161\n",
      "Configuration saved in clinico-finetuned/checkpoint-161/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-161/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-161/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-161/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-168\n",
      "Configuration saved in clinico-finetuned/checkpoint-168/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-168/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-168/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-168/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-175\n",
      "Configuration saved in clinico-finetuned/checkpoint-175/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-175/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-175/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-175/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-182\n",
      "Configuration saved in clinico-finetuned/checkpoint-182/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-182/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-182/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-182/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-189\n",
      "Configuration saved in clinico-finetuned/checkpoint-189/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-189/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-189/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-189/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-196\n",
      "Configuration saved in clinico-finetuned/checkpoint-196/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-196/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-196/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-196/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-203\n",
      "Configuration saved in clinico-finetuned/checkpoint-203/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-203/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-203/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-203/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-210\n",
      "Configuration saved in clinico-finetuned/checkpoint-210/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-210/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-210/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-210/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-217\n",
      "Configuration saved in clinico-finetuned/checkpoint-217/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-217/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-217/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-217/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-224\n",
      "Configuration saved in clinico-finetuned/checkpoint-224/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-224/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-224/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-224/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-231\n",
      "Configuration saved in clinico-finetuned/checkpoint-231/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-231/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-231/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-231/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-238\n",
      "Configuration saved in clinico-finetuned/checkpoint-238/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-238/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-238/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-238/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-245\n",
      "Configuration saved in clinico-finetuned/checkpoint-245/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-245/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-245/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-245/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-252\n",
      "Configuration saved in clinico-finetuned/checkpoint-252/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-252/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-252/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-252/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-259\n",
      "Configuration saved in clinico-finetuned/checkpoint-259/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-259/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-259/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-259/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-266\n",
      "Configuration saved in clinico-finetuned/checkpoint-266/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-266/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-266/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-266/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-273\n",
      "Configuration saved in clinico-finetuned/checkpoint-273/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-273/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-273/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-273/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-280\n",
      "Configuration saved in clinico-finetuned/checkpoint-280/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-280/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-280/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-280/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-287\n",
      "Configuration saved in clinico-finetuned/checkpoint-287/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-287/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-287/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-287/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-294\n",
      "Configuration saved in clinico-finetuned/checkpoint-294/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-294/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-294/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-294/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-301\n",
      "Configuration saved in clinico-finetuned/checkpoint-301/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-301/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-301/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-301/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-308\n",
      "Configuration saved in clinico-finetuned/checkpoint-308/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-308/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-308/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-308/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-315\n",
      "Configuration saved in clinico-finetuned/checkpoint-315/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-315/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-315/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-315/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-322\n",
      "Configuration saved in clinico-finetuned/checkpoint-322/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-322/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-322/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-322/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-329\n",
      "Configuration saved in clinico-finetuned/checkpoint-329/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-329/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-329/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-329/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-336\n",
      "Configuration saved in clinico-finetuned/checkpoint-336/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-336/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-336/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-336/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-343\n",
      "Configuration saved in clinico-finetuned/checkpoint-343/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-343/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-343/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-343/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-350\n",
      "Configuration saved in clinico-finetuned/checkpoint-350/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-350/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-357\n",
      "Configuration saved in clinico-finetuned/checkpoint-357/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-357/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-357/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-357/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-364\n",
      "Configuration saved in clinico-finetuned/checkpoint-364/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-364/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-364/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-364/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-371\n",
      "Configuration saved in clinico-finetuned/checkpoint-371/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-371/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-371/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-371/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-378\n",
      "Configuration saved in clinico-finetuned/checkpoint-378/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-378/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-378/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-378/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-385\n",
      "Configuration saved in clinico-finetuned/checkpoint-385/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-385/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-385/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-385/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-392\n",
      "Configuration saved in clinico-finetuned/checkpoint-392/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-392/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-392/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-392/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-399\n",
      "Configuration saved in clinico-finetuned/checkpoint-399/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-399/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-399/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-399/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-406\n",
      "Configuration saved in clinico-finetuned/checkpoint-406/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-406/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-406/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-406/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-413\n",
      "Configuration saved in clinico-finetuned/checkpoint-413/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-413/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-413/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-413/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-420\n",
      "Configuration saved in clinico-finetuned/checkpoint-420/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-420/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-420/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-420/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-427\n",
      "Configuration saved in clinico-finetuned/checkpoint-427/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-427/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-427/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-427/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-434\n",
      "Configuration saved in clinico-finetuned/checkpoint-434/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-434/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-434/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-434/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-441\n",
      "Configuration saved in clinico-finetuned/checkpoint-441/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-441/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-441/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-441/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-448\n",
      "Configuration saved in clinico-finetuned/checkpoint-448/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-448/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-448/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-448/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-455\n",
      "Configuration saved in clinico-finetuned/checkpoint-455/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-455/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-455/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-455/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-462\n",
      "Configuration saved in clinico-finetuned/checkpoint-462/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-462/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-462/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-462/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-469\n",
      "Configuration saved in clinico-finetuned/checkpoint-469/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-469/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-469/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-469/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-476\n",
      "Configuration saved in clinico-finetuned/checkpoint-476/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-476/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-476/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-476/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-483\n",
      "Configuration saved in clinico-finetuned/checkpoint-483/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-483/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-483/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-483/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-490\n",
      "Configuration saved in clinico-finetuned/checkpoint-490/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-490/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-490/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-490/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-497\n",
      "Configuration saved in clinico-finetuned/checkpoint-497/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-497/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-497/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-497/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-504\n",
      "Configuration saved in clinico-finetuned/checkpoint-504/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-504/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-504/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-504/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-511\n",
      "Configuration saved in clinico-finetuned/checkpoint-511/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-511/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-511/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-511/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-518\n",
      "Configuration saved in clinico-finetuned/checkpoint-518/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-518/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-518/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-518/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-525\n",
      "Configuration saved in clinico-finetuned/checkpoint-525/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-525/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-525/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-525/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-532\n",
      "Configuration saved in clinico-finetuned/checkpoint-532/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-532/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-532/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-532/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-539\n",
      "Configuration saved in clinico-finetuned/checkpoint-539/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-539/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-539/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-539/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-546\n",
      "Configuration saved in clinico-finetuned/checkpoint-546/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-546/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-546/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-546/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-553\n",
      "Configuration saved in clinico-finetuned/checkpoint-553/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-553/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-553/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-553/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-560\n",
      "Configuration saved in clinico-finetuned/checkpoint-560/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-560/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-560/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-560/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-567\n",
      "Configuration saved in clinico-finetuned/checkpoint-567/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-567/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-567/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-567/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-574\n",
      "Configuration saved in clinico-finetuned/checkpoint-574/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-574/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-574/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-574/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-581\n",
      "Configuration saved in clinico-finetuned/checkpoint-581/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-581/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-581/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-581/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-588\n",
      "Configuration saved in clinico-finetuned/checkpoint-588/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-588/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-588/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-588/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-595\n",
      "Configuration saved in clinico-finetuned/checkpoint-595/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-595/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-595/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-595/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-602\n",
      "Configuration saved in clinico-finetuned/checkpoint-602/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-602/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-602/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-602/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-609\n",
      "Configuration saved in clinico-finetuned/checkpoint-609/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-609/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-609/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-609/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-616\n",
      "Configuration saved in clinico-finetuned/checkpoint-616/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-616/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-616/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-616/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-623\n",
      "Configuration saved in clinico-finetuned/checkpoint-623/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-623/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-623/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-623/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-630\n",
      "Configuration saved in clinico-finetuned/checkpoint-630/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-630/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-630/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-630/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-637\n",
      "Configuration saved in clinico-finetuned/checkpoint-637/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-637/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-637/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-637/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-644\n",
      "Configuration saved in clinico-finetuned/checkpoint-644/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-644/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-644/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-644/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-651\n",
      "Configuration saved in clinico-finetuned/checkpoint-651/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-651/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-651/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-651/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-658\n",
      "Configuration saved in clinico-finetuned/checkpoint-658/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-658/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-658/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-658/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-665\n",
      "Configuration saved in clinico-finetuned/checkpoint-665/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-665/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-665/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-665/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-672\n",
      "Configuration saved in clinico-finetuned/checkpoint-672/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-672/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-672/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-672/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-679\n",
      "Configuration saved in clinico-finetuned/checkpoint-679/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-679/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-679/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-679/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-686\n",
      "Configuration saved in clinico-finetuned/checkpoint-686/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-686/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-686/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-686/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-693\n",
      "Configuration saved in clinico-finetuned/checkpoint-693/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-693/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-693/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-693/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-700\n",
      "Configuration saved in clinico-finetuned/checkpoint-700/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-700/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-700/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-700/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-707\n",
      "Configuration saved in clinico-finetuned/checkpoint-707/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-707/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-707/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-707/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-714\n",
      "Configuration saved in clinico-finetuned/checkpoint-714/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-714/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-714/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-714/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-721\n",
      "Configuration saved in clinico-finetuned/checkpoint-721/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-721/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-721/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-721/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-728\n",
      "Configuration saved in clinico-finetuned/checkpoint-728/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-728/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-728/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-728/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-735\n",
      "Configuration saved in clinico-finetuned/checkpoint-735/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-735/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-735/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-735/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-742\n",
      "Configuration saved in clinico-finetuned/checkpoint-742/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-742/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-742/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-742/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-749\n",
      "Configuration saved in clinico-finetuned/checkpoint-749/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-749/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-749/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-749/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-756\n",
      "Configuration saved in clinico-finetuned/checkpoint-756/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-756/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-756/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-756/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-763\n",
      "Configuration saved in clinico-finetuned/checkpoint-763/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-763/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-763/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-763/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-770\n",
      "Configuration saved in clinico-finetuned/checkpoint-770/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-770/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-770/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-770/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-777\n",
      "Configuration saved in clinico-finetuned/checkpoint-777/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-777/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-777/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-777/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-784\n",
      "Configuration saved in clinico-finetuned/checkpoint-784/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-784/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-784/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-784/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-791\n",
      "Configuration saved in clinico-finetuned/checkpoint-791/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-791/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-791/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-791/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-798\n",
      "Configuration saved in clinico-finetuned/checkpoint-798/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-798/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-798/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-798/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-805\n",
      "Configuration saved in clinico-finetuned/checkpoint-805/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-805/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-805/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-805/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-812\n",
      "Configuration saved in clinico-finetuned/checkpoint-812/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-812/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-812/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-812/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-819\n",
      "Configuration saved in clinico-finetuned/checkpoint-819/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-819/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-819/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-819/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-826\n",
      "Configuration saved in clinico-finetuned/checkpoint-826/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-826/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-826/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-826/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-833\n",
      "Configuration saved in clinico-finetuned/checkpoint-833/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-833/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-833/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-833/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-840\n",
      "Configuration saved in clinico-finetuned/checkpoint-840/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-840/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-840/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-840/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-847\n",
      "Configuration saved in clinico-finetuned/checkpoint-847/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-847/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-847/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-847/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-854\n",
      "Configuration saved in clinico-finetuned/checkpoint-854/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-854/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-854/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-854/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-861\n",
      "Configuration saved in clinico-finetuned/checkpoint-861/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-861/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-861/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-861/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-868\n",
      "Configuration saved in clinico-finetuned/checkpoint-868/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-868/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-868/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-868/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-875\n",
      "Configuration saved in clinico-finetuned/checkpoint-875/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-875/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-875/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-875/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-882\n",
      "Configuration saved in clinico-finetuned/checkpoint-882/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-882/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-882/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-882/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-889\n",
      "Configuration saved in clinico-finetuned/checkpoint-889/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-889/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-889/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-889/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-896\n",
      "Configuration saved in clinico-finetuned/checkpoint-896/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-896/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-896/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-896/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-903\n",
      "Configuration saved in clinico-finetuned/checkpoint-903/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-903/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-903/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-903/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-910\n",
      "Configuration saved in clinico-finetuned/checkpoint-910/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-910/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-910/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-910/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-917\n",
      "Configuration saved in clinico-finetuned/checkpoint-917/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-917/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-917/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-917/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-924\n",
      "Configuration saved in clinico-finetuned/checkpoint-924/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-924/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-924/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-924/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-931\n",
      "Configuration saved in clinico-finetuned/checkpoint-931/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-931/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-931/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-931/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-938\n",
      "Configuration saved in clinico-finetuned/checkpoint-938/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-938/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-938/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-938/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-945\n",
      "Configuration saved in clinico-finetuned/checkpoint-945/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-945/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-945/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-945/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-952\n",
      "Configuration saved in clinico-finetuned/checkpoint-952/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-952/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-952/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-952/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-959\n",
      "Configuration saved in clinico-finetuned/checkpoint-959/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-959/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-959/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-959/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-966\n",
      "Configuration saved in clinico-finetuned/checkpoint-966/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-966/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-966/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-966/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-973\n",
      "Configuration saved in clinico-finetuned/checkpoint-973/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-973/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-973/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-973/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-980\n",
      "Configuration saved in clinico-finetuned/checkpoint-980/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-980/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-980/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-980/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-987\n",
      "Configuration saved in clinico-finetuned/checkpoint-987/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-987/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-987/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-987/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-994\n",
      "Configuration saved in clinico-finetuned/checkpoint-994/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-994/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-994/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-994/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1001\n",
      "Configuration saved in clinico-finetuned/checkpoint-1001/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1001/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1001/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1001/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1008\n",
      "Configuration saved in clinico-finetuned/checkpoint-1008/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1008/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1008/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1008/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1015\n",
      "Configuration saved in clinico-finetuned/checkpoint-1015/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1015/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1015/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1015/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1022\n",
      "Configuration saved in clinico-finetuned/checkpoint-1022/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1022/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1022/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1022/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1029\n",
      "Configuration saved in clinico-finetuned/checkpoint-1029/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1029/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1029/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1029/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1036\n",
      "Configuration saved in clinico-finetuned/checkpoint-1036/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1036/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1036/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1036/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1043\n",
      "Configuration saved in clinico-finetuned/checkpoint-1043/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1043/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1043/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1043/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1050\n",
      "Configuration saved in clinico-finetuned/checkpoint-1050/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1050/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1050/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1050/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1057\n",
      "Configuration saved in clinico-finetuned/checkpoint-1057/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1057/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1057/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1057/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1064\n",
      "Configuration saved in clinico-finetuned/checkpoint-1064/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1064/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1064/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1064/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1071\n",
      "Configuration saved in clinico-finetuned/checkpoint-1071/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1071/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1071/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1071/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1078\n",
      "Configuration saved in clinico-finetuned/checkpoint-1078/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1078/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1078/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1078/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1085\n",
      "Configuration saved in clinico-finetuned/checkpoint-1085/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1085/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1085/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1085/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1092\n",
      "Configuration saved in clinico-finetuned/checkpoint-1092/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1092/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1092/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1092/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1099\n",
      "Configuration saved in clinico-finetuned/checkpoint-1099/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1099/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1099/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1099/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1106\n",
      "Configuration saved in clinico-finetuned/checkpoint-1106/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1106/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1106/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1106/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1113\n",
      "Configuration saved in clinico-finetuned/checkpoint-1113/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1113/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1113/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1113/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1120\n",
      "Configuration saved in clinico-finetuned/checkpoint-1120/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1120/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1120/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1120/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1127\n",
      "Configuration saved in clinico-finetuned/checkpoint-1127/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1127/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1127/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1127/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1134\n",
      "Configuration saved in clinico-finetuned/checkpoint-1134/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1134/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1134/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1134/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1141\n",
      "Configuration saved in clinico-finetuned/checkpoint-1141/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1141/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1141/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1141/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1148\n",
      "Configuration saved in clinico-finetuned/checkpoint-1148/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1148/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1148/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1148/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1155\n",
      "Configuration saved in clinico-finetuned/checkpoint-1155/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1155/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1155/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1155/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1162\n",
      "Configuration saved in clinico-finetuned/checkpoint-1162/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1162/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1162/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1162/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1169\n",
      "Configuration saved in clinico-finetuned/checkpoint-1169/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1169/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1169/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1169/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1176\n",
      "Configuration saved in clinico-finetuned/checkpoint-1176/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1176/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1176/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1176/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1183\n",
      "Configuration saved in clinico-finetuned/checkpoint-1183/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1183/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1183/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1183/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1190\n",
      "Configuration saved in clinico-finetuned/checkpoint-1190/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1190/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1190/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1190/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1197\n",
      "Configuration saved in clinico-finetuned/checkpoint-1197/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1197/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1197/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1197/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1204\n",
      "Configuration saved in clinico-finetuned/checkpoint-1204/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1204/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1204/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1204/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1211\n",
      "Configuration saved in clinico-finetuned/checkpoint-1211/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1211/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1211/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1211/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1218\n",
      "Configuration saved in clinico-finetuned/checkpoint-1218/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1218/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1218/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1218/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1225\n",
      "Configuration saved in clinico-finetuned/checkpoint-1225/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1225/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1225/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1225/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1232\n",
      "Configuration saved in clinico-finetuned/checkpoint-1232/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1232/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1232/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1232/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1239\n",
      "Configuration saved in clinico-finetuned/checkpoint-1239/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1239/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1239/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1239/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1246\n",
      "Configuration saved in clinico-finetuned/checkpoint-1246/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1246/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1246/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1246/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1253\n",
      "Configuration saved in clinico-finetuned/checkpoint-1253/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1253/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1253/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1253/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1260\n",
      "Configuration saved in clinico-finetuned/checkpoint-1260/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1260/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1260/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1260/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1267\n",
      "Configuration saved in clinico-finetuned/checkpoint-1267/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1267/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1267/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1267/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1274\n",
      "Configuration saved in clinico-finetuned/checkpoint-1274/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1274/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1274/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1274/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1281\n",
      "Configuration saved in clinico-finetuned/checkpoint-1281/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1281/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1281/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1281/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1288\n",
      "Configuration saved in clinico-finetuned/checkpoint-1288/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1288/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1288/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1288/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1295\n",
      "Configuration saved in clinico-finetuned/checkpoint-1295/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1295/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1295/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1295/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1302\n",
      "Configuration saved in clinico-finetuned/checkpoint-1302/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1302/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1302/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1302/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1309\n",
      "Configuration saved in clinico-finetuned/checkpoint-1309/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1309/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1309/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1309/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1316\n",
      "Configuration saved in clinico-finetuned/checkpoint-1316/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1316/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1316/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1316/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1323\n",
      "Configuration saved in clinico-finetuned/checkpoint-1323/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1323/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1323/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1323/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1330\n",
      "Configuration saved in clinico-finetuned/checkpoint-1330/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1330/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1330/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1330/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1337\n",
      "Configuration saved in clinico-finetuned/checkpoint-1337/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1337/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1337/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1337/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1344\n",
      "Configuration saved in clinico-finetuned/checkpoint-1344/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1344/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1344/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1344/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1351\n",
      "Configuration saved in clinico-finetuned/checkpoint-1351/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1351/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1351/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1351/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1358\n",
      "Configuration saved in clinico-finetuned/checkpoint-1358/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1358/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1358/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1358/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1365\n",
      "Configuration saved in clinico-finetuned/checkpoint-1365/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1365/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1365/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1365/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1372\n",
      "Configuration saved in clinico-finetuned/checkpoint-1372/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1372/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1372/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1372/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1379\n",
      "Configuration saved in clinico-finetuned/checkpoint-1379/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1379/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1379/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1379/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1386\n",
      "Configuration saved in clinico-finetuned/checkpoint-1386/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1386/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1386/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1386/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1393\n",
      "Configuration saved in clinico-finetuned/checkpoint-1393/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1393/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1393/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1393/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1400\n",
      "Configuration saved in clinico-finetuned/checkpoint-1400/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1400/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1400/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1400/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1407\n",
      "Configuration saved in clinico-finetuned/checkpoint-1407/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1407/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1407/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1407/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1414\n",
      "Configuration saved in clinico-finetuned/checkpoint-1414/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1414/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1414/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1414/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1421\n",
      "Configuration saved in clinico-finetuned/checkpoint-1421/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1421/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1421/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1421/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1428\n",
      "Configuration saved in clinico-finetuned/checkpoint-1428/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1428/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1428/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1428/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1435\n",
      "Configuration saved in clinico-finetuned/checkpoint-1435/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1435/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1435/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1435/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1442\n",
      "Configuration saved in clinico-finetuned/checkpoint-1442/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1442/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1442/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1442/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1449\n",
      "Configuration saved in clinico-finetuned/checkpoint-1449/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1449/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1449/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1449/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1456\n",
      "Configuration saved in clinico-finetuned/checkpoint-1456/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1456/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1456/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1456/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1463\n",
      "Configuration saved in clinico-finetuned/checkpoint-1463/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1463/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1463/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1463/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1470\n",
      "Configuration saved in clinico-finetuned/checkpoint-1470/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1470/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1470/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1470/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1477\n",
      "Configuration saved in clinico-finetuned/checkpoint-1477/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1477/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1477/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1477/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1484\n",
      "Configuration saved in clinico-finetuned/checkpoint-1484/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1484/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1484/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1484/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1491\n",
      "Configuration saved in clinico-finetuned/checkpoint-1491/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1491/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1491/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1491/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1498\n",
      "Configuration saved in clinico-finetuned/checkpoint-1498/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1498/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1498/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1498/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1505\n",
      "Configuration saved in clinico-finetuned/checkpoint-1505/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1505/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1505/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1505/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1512\n",
      "Configuration saved in clinico-finetuned/checkpoint-1512/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1512/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1512/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1512/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1519\n",
      "Configuration saved in clinico-finetuned/checkpoint-1519/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1519/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1519/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1519/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1526\n",
      "Configuration saved in clinico-finetuned/checkpoint-1526/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1526/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1526/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1526/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1533\n",
      "Configuration saved in clinico-finetuned/checkpoint-1533/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1533/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1533/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1533/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1540\n",
      "Configuration saved in clinico-finetuned/checkpoint-1540/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1540/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1540/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1540/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1547\n",
      "Configuration saved in clinico-finetuned/checkpoint-1547/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1547/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1547/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1547/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1554\n",
      "Configuration saved in clinico-finetuned/checkpoint-1554/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1554/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1554/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1554/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1561\n",
      "Configuration saved in clinico-finetuned/checkpoint-1561/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1561/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1561/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1561/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1568\n",
      "Configuration saved in clinico-finetuned/checkpoint-1568/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1568/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1568/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1568/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1575\n",
      "Configuration saved in clinico-finetuned/checkpoint-1575/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1575/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1575/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1575/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1582\n",
      "Configuration saved in clinico-finetuned/checkpoint-1582/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1582/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1582/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1582/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1589\n",
      "Configuration saved in clinico-finetuned/checkpoint-1589/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1589/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1589/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1589/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1596\n",
      "Configuration saved in clinico-finetuned/checkpoint-1596/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1596/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1596/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1596/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1603\n",
      "Configuration saved in clinico-finetuned/checkpoint-1603/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1603/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1603/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1603/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1610\n",
      "Configuration saved in clinico-finetuned/checkpoint-1610/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1610/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1610/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1610/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1617\n",
      "Configuration saved in clinico-finetuned/checkpoint-1617/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1617/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1617/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1617/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1624\n",
      "Configuration saved in clinico-finetuned/checkpoint-1624/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1624/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1624/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1624/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1631\n",
      "Configuration saved in clinico-finetuned/checkpoint-1631/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1631/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1631/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1631/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1638\n",
      "Configuration saved in clinico-finetuned/checkpoint-1638/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1638/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1638/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1638/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1645\n",
      "Configuration saved in clinico-finetuned/checkpoint-1645/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1645/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1645/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1645/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1652\n",
      "Configuration saved in clinico-finetuned/checkpoint-1652/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1652/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1652/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1652/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1659\n",
      "Configuration saved in clinico-finetuned/checkpoint-1659/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1659/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1659/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1659/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1666\n",
      "Configuration saved in clinico-finetuned/checkpoint-1666/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1666/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1666/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1666/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1673\n",
      "Configuration saved in clinico-finetuned/checkpoint-1673/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1673/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1673/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1673/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1680\n",
      "Configuration saved in clinico-finetuned/checkpoint-1680/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1680/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1680/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1680/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1687\n",
      "Configuration saved in clinico-finetuned/checkpoint-1687/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1687/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1687/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1687/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1694\n",
      "Configuration saved in clinico-finetuned/checkpoint-1694/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1694/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1694/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1694/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1701\n",
      "Configuration saved in clinico-finetuned/checkpoint-1701/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1701/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1701/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1701/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1708\n",
      "Configuration saved in clinico-finetuned/checkpoint-1708/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1708/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1708/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1708/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1715\n",
      "Configuration saved in clinico-finetuned/checkpoint-1715/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1715/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1715/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1715/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1722\n",
      "Configuration saved in clinico-finetuned/checkpoint-1722/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1722/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1722/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1722/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1729\n",
      "Configuration saved in clinico-finetuned/checkpoint-1729/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1729/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1729/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1729/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1736\n",
      "Configuration saved in clinico-finetuned/checkpoint-1736/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1736/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1736/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1736/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1743\n",
      "Configuration saved in clinico-finetuned/checkpoint-1743/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1743/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1743/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1743/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1750\n",
      "Configuration saved in clinico-finetuned/checkpoint-1750/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1750/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1750/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1750/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1757\n",
      "Configuration saved in clinico-finetuned/checkpoint-1757/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1757/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1757/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1757/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1764\n",
      "Configuration saved in clinico-finetuned/checkpoint-1764/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1764/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1764/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1764/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1771\n",
      "Configuration saved in clinico-finetuned/checkpoint-1771/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1771/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1771/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1771/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1778\n",
      "Configuration saved in clinico-finetuned/checkpoint-1778/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1778/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1778/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1778/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1785\n",
      "Configuration saved in clinico-finetuned/checkpoint-1785/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1785/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1785/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1785/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1792\n",
      "Configuration saved in clinico-finetuned/checkpoint-1792/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1792/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1792/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1792/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1799\n",
      "Configuration saved in clinico-finetuned/checkpoint-1799/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1799/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1799/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1799/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1806\n",
      "Configuration saved in clinico-finetuned/checkpoint-1806/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1806/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1806/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1806/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1813\n",
      "Configuration saved in clinico-finetuned/checkpoint-1813/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1813/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1813/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1813/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1820\n",
      "Configuration saved in clinico-finetuned/checkpoint-1820/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1820/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1820/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1820/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1827\n",
      "Configuration saved in clinico-finetuned/checkpoint-1827/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1827/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1827/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1827/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1834\n",
      "Configuration saved in clinico-finetuned/checkpoint-1834/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1834/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1834/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1834/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1841\n",
      "Configuration saved in clinico-finetuned/checkpoint-1841/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1841/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1841/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1841/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1848\n",
      "Configuration saved in clinico-finetuned/checkpoint-1848/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1848/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1848/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1848/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1855\n",
      "Configuration saved in clinico-finetuned/checkpoint-1855/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1855/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1855/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1855/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1862\n",
      "Configuration saved in clinico-finetuned/checkpoint-1862/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1862/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1862/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1862/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1869\n",
      "Configuration saved in clinico-finetuned/checkpoint-1869/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1869/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1869/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1869/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1876\n",
      "Configuration saved in clinico-finetuned/checkpoint-1876/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1876/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1876/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1883\n",
      "Configuration saved in clinico-finetuned/checkpoint-1883/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1883/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1883/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1883/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1890\n",
      "Configuration saved in clinico-finetuned/checkpoint-1890/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1890/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1890/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1890/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1897\n",
      "Configuration saved in clinico-finetuned/checkpoint-1897/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1897/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1897/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1897/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1904\n",
      "Configuration saved in clinico-finetuned/checkpoint-1904/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1904/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1904/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1904/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1911\n",
      "Configuration saved in clinico-finetuned/checkpoint-1911/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1911/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1911/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1911/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1918\n",
      "Configuration saved in clinico-finetuned/checkpoint-1918/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1918/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1918/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1918/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1925\n",
      "Configuration saved in clinico-finetuned/checkpoint-1925/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1925/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1925/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1925/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1932\n",
      "Configuration saved in clinico-finetuned/checkpoint-1932/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1932/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1932/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1932/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1939\n",
      "Configuration saved in clinico-finetuned/checkpoint-1939/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1939/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1939/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1939/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1946\n",
      "Configuration saved in clinico-finetuned/checkpoint-1946/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1946/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1946/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1946/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1953\n",
      "Configuration saved in clinico-finetuned/checkpoint-1953/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1953/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1953/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1953/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1960\n",
      "Configuration saved in clinico-finetuned/checkpoint-1960/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1960/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1960/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1960/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1967\n",
      "Configuration saved in clinico-finetuned/checkpoint-1967/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1967/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1967/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1967/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1974\n",
      "Configuration saved in clinico-finetuned/checkpoint-1974/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1974/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1974/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1974/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1981\n",
      "Configuration saved in clinico-finetuned/checkpoint-1981/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1981/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1981/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1981/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1988\n",
      "Configuration saved in clinico-finetuned/checkpoint-1988/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1988/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1988/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1988/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-1995\n",
      "Configuration saved in clinico-finetuned/checkpoint-1995/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-1995/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-1995/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-1995/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2002\n",
      "Configuration saved in clinico-finetuned/checkpoint-2002/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2002/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2002/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2002/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2009\n",
      "Configuration saved in clinico-finetuned/checkpoint-2009/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2009/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2009/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2009/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2016\n",
      "Configuration saved in clinico-finetuned/checkpoint-2016/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2016/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2016/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2016/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2023\n",
      "Configuration saved in clinico-finetuned/checkpoint-2023/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2023/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2023/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2023/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2030\n",
      "Configuration saved in clinico-finetuned/checkpoint-2030/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2030/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2030/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2030/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2037\n",
      "Configuration saved in clinico-finetuned/checkpoint-2037/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2037/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2037/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2037/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2044\n",
      "Configuration saved in clinico-finetuned/checkpoint-2044/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2044/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2044/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2044/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2051\n",
      "Configuration saved in clinico-finetuned/checkpoint-2051/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2051/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2051/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2051/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2058\n",
      "Configuration saved in clinico-finetuned/checkpoint-2058/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2058/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2058/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2058/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2065\n",
      "Configuration saved in clinico-finetuned/checkpoint-2065/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2065/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2065/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2065/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2072\n",
      "Configuration saved in clinico-finetuned/checkpoint-2072/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2072/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2072/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2072/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2079\n",
      "Configuration saved in clinico-finetuned/checkpoint-2079/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2079/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2079/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2079/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2086\n",
      "Configuration saved in clinico-finetuned/checkpoint-2086/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2086/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2086/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2086/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2093\n",
      "Configuration saved in clinico-finetuned/checkpoint-2093/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2093/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2093/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2093/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, tags. If tokens, id, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned/checkpoint-2100\n",
      "Configuration saved in clinico-finetuned/checkpoint-2100/config.json\n",
      "Model weights saved in clinico-finetuned/checkpoint-2100/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/checkpoint-2100/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/checkpoint-2100/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from clinico-finetuned/checkpoint-308 (score: 0.6821034550666809).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2100, training_loss=0.14884440246082487, metrics={'train_runtime': 2467.6851, 'train_samples_per_second': 94.947, 'train_steps_per_second': 0.851, 'total_flos': 3.06186633713664e+16, 'train_loss': 0.14884440246082487, 'epoch': 300.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"clinico-finetuned\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=300,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dab37a4b-6ba8-40c2-b570-a57d653ba06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to clinico-finetuned\n",
      "Configuration saved in clinico-finetuned/config.json\n",
      "Model weights saved in clinico-finetuned/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned/special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02019357681274414,
       "initial": 32768,
       "n": 32768,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file pytorch_model.bin",
       "rate": null,
       "total": 267003941,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03386ad11f36432fb0d2ba8080091d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017641305923461914,
       "initial": 32768,
       "n": 32768,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file runs/Mar16_08-02-28_minion/events.out.tfevents.1678950154.minion.4092817.0",
       "rate": null,
       "total": 147055,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d38b74ec878409eaf246462686faefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Mar16_08-02-28_minion/events.out.tfevents.1678950154.minion.4092817.0:  22%|##2       | 32.0k…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files of refs/heads/main for validity...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/joheras/clinico-finetuned\n",
      "   334b033..9c3662d  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'metrics': [{'name': 'Precision', 'type': 'precision', 'value': 0.30039267015706805}, {'name': 'Recall', 'type': 'recall', 'value': 0.51}, {'name': 'F1', 'type': 'f1', 'value': 0.37808896210873144}, {'name': 'Accuracy', 'type': 'accuracy', 'value': 0.8204365390035386}]}\n",
      "To https://huggingface.co/joheras/clinico-finetuned\n",
      "   9c3662d..ccf1c55  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/joheras/clinico-finetuned/commit/9c3662d1d544942dad59b3c02e6e5dbfa627196a'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d5781-2f12-4b75-8de4-c998d6e6cbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
