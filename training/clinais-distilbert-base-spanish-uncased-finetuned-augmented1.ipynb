{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98418b43-333d-40de-b56e-41c45bf024f7",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d4745-0a32-4c26-ac7b-8c9d97d780a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:00<00:00, 9240.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('clinais.train.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "finalresult = []\n",
    "for key in tqdm(data['annotated_entries'].keys()):\n",
    "    ident = data['annotated_entries'][key]['note_id']\n",
    "    res = []\n",
    "    tags = []\n",
    "    gold = data['annotated_entries'][key]['boundary_annotation']['gold']\n",
    "    currentboundary = ''\n",
    "    for g in gold:\n",
    "        res.append(g['span'])\n",
    "        if(g['boundary'] is None):\n",
    "            tags.append('I-'+currentboundary)\n",
    "        else:\n",
    "            currentboundary = g['boundary']\n",
    "            tags.append('B-'+currentboundary)\n",
    "    finalresult.append([ident,res,tags])\n",
    "\n",
    "# finalresult    \n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "tags = [x[2] for x in finalresult]\n",
    "tags = np.unique(list(itertools.chain(*tags)))\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "for i,tag in enumerate(tags):\n",
    "    id2label[i] = tag\n",
    "    label2id[tag] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cbb09f7-6929-4c4d-986a-4f8335ff5e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joheras/.local/lib/python3.10/site-packages/datasets/dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('augmented_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b882d9f-4bfe-480f-b4f5-060a41dcdcd6",
   "metadata": {},
   "source": [
    "# Processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a648f87-9723-4a08-8862-138070fddf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fd9ef6f-d9fb-4752-a340-7f7bb7f14c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheckpoint = \"joheras/distilbert-base-spanish-uncased-finetuned-clinais\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1500c3d7-fe6a-431f-b6f9-171424b19ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81627bc7-d56b-4e52-aaeb-8fb0566ddee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017740249633789062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73940051673d438fa0eb065a4a3b0c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012305021286010742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39895f0599d44ee6871ac05de75b3a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8809a5b8-e25e-478f-8399-61825f24b47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2850\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 127\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46773083-a305-4650-a205-f67c2c122f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28c1426-2367-41d9-a305-55fa1e7623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67009bec-f535-4155-9e80-aa7faa0af0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b702405b-6458-4c6e-a6a0-19d350926b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joheras/distilbert-base-spanish-uncased-finetuned-clinais were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at joheras/distilbert-base-spanish-uncased-finetuned-clinais and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    modelCheckpoint, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd829ef-beac-4d3a-972f-813578a8d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/joheras/clinico-finetuned-augmented1 into local empty directory.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/joheras/.local/lib/python3.10/site-packages/transformers/optimization.py:346: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2850\n",
      "  Num Epochs = 300\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6900\n",
      "  Number of trainable parameters = 66349070\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoheras\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joheras/CLINAIS/wandb/run-20230317_101507-d1klz4hj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/joheras/huggingface/runs/d1klz4hj\" target=\"_blank\">pleasant-lake-118</a></strong> to <a href=\"https://wandb.ai/joheras/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6900' max='6900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6900/6900 1:55:19, Epoch 300/300]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.347083</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.554787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.038590</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.034444</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>0.652679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.908844</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.056949</td>\n",
       "      <td>0.712460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.818948</td>\n",
       "      <td>0.060366</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.083533</td>\n",
       "      <td>0.744559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.748396</td>\n",
       "      <td>0.094318</td>\n",
       "      <td>0.184444</td>\n",
       "      <td>0.124812</td>\n",
       "      <td>0.770426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709403</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.777158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702202</td>\n",
       "      <td>0.116921</td>\n",
       "      <td>0.221111</td>\n",
       "      <td>0.152959</td>\n",
       "      <td>0.780039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.677576</td>\n",
       "      <td>0.157543</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.203616</td>\n",
       "      <td>0.794413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.698344</td>\n",
       "      <td>0.149288</td>\n",
       "      <td>0.291111</td>\n",
       "      <td>0.197363</td>\n",
       "      <td>0.796355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.682146</td>\n",
       "      <td>0.177208</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.230590</td>\n",
       "      <td>0.802086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684523</td>\n",
       "      <td>0.186101</td>\n",
       "      <td>0.351111</td>\n",
       "      <td>0.243264</td>\n",
       "      <td>0.805342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.202032</td>\n",
       "      <td>0.375556</td>\n",
       "      <td>0.262728</td>\n",
       "      <td>0.810603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697333</td>\n",
       "      <td>0.209753</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.274404</td>\n",
       "      <td>0.810165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.722966</td>\n",
       "      <td>0.214037</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.813986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744756</td>\n",
       "      <td>0.224310</td>\n",
       "      <td>0.424444</td>\n",
       "      <td>0.293507</td>\n",
       "      <td>0.810040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.751910</td>\n",
       "      <td>0.237801</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.305677</td>\n",
       "      <td>0.811105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.750334</td>\n",
       "      <td>0.232586</td>\n",
       "      <td>0.437778</td>\n",
       "      <td>0.303778</td>\n",
       "      <td>0.811887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.757251</td>\n",
       "      <td>0.249378</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.319777</td>\n",
       "      <td>0.813923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.797042</td>\n",
       "      <td>0.243452</td>\n",
       "      <td>0.454444</td>\n",
       "      <td>0.317054</td>\n",
       "      <td>0.813735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>0.252331</td>\n",
       "      <td>0.451111</td>\n",
       "      <td>0.323635</td>\n",
       "      <td>0.816961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.811492</td>\n",
       "      <td>0.248362</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.323381</td>\n",
       "      <td>0.813923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.813453</td>\n",
       "      <td>0.257195</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.331623</td>\n",
       "      <td>0.815677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.850852</td>\n",
       "      <td>0.264353</td>\n",
       "      <td>0.465556</td>\n",
       "      <td>0.337223</td>\n",
       "      <td>0.810791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.845038</td>\n",
       "      <td>0.259952</td>\n",
       "      <td>0.478889</td>\n",
       "      <td>0.336982</td>\n",
       "      <td>0.814330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.866709</td>\n",
       "      <td>0.277742</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>0.352176</td>\n",
       "      <td>0.821971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.863884</td>\n",
       "      <td>0.263352</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.339265</td>\n",
       "      <td>0.815238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.890262</td>\n",
       "      <td>0.278995</td>\n",
       "      <td>0.481111</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.815426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.869699</td>\n",
       "      <td>0.288474</td>\n",
       "      <td>0.497778</td>\n",
       "      <td>0.365267</td>\n",
       "      <td>0.821157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.885643</td>\n",
       "      <td>0.285062</td>\n",
       "      <td>0.485556</td>\n",
       "      <td>0.359227</td>\n",
       "      <td>0.819654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.933230</td>\n",
       "      <td>0.266987</td>\n",
       "      <td>0.493333</td>\n",
       "      <td>0.346469</td>\n",
       "      <td>0.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.906427</td>\n",
       "      <td>0.292949</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.925613</td>\n",
       "      <td>0.291534</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.944657</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.374541</td>\n",
       "      <td>0.817493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.938727</td>\n",
       "      <td>0.299805</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.378533</td>\n",
       "      <td>0.819904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.954484</td>\n",
       "      <td>0.312417</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.390325</td>\n",
       "      <td>0.822535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.978534</td>\n",
       "      <td>0.296224</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.373563</td>\n",
       "      <td>0.817900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.963501</td>\n",
       "      <td>0.300390</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.378999</td>\n",
       "      <td>0.820123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.974925</td>\n",
       "      <td>0.280997</td>\n",
       "      <td>0.501111</td>\n",
       "      <td>0.360080</td>\n",
       "      <td>0.822910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.975255</td>\n",
       "      <td>0.301839</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>0.384336</td>\n",
       "      <td>0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.973532</td>\n",
       "      <td>0.300130</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.378489</td>\n",
       "      <td>0.822065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>1.019637</td>\n",
       "      <td>0.303251</td>\n",
       "      <td>0.507778</td>\n",
       "      <td>0.379726</td>\n",
       "      <td>0.817869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>0.977548</td>\n",
       "      <td>0.303652</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.385209</td>\n",
       "      <td>0.825384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.467500</td>\n",
       "      <td>1.005124</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.380874</td>\n",
       "      <td>0.822065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.005255</td>\n",
       "      <td>0.306744</td>\n",
       "      <td>0.525556</td>\n",
       "      <td>0.387387</td>\n",
       "      <td>0.825040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.014546</td>\n",
       "      <td>0.308974</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.391870</td>\n",
       "      <td>0.822535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.029916</td>\n",
       "      <td>0.308094</td>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.388158</td>\n",
       "      <td>0.821157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.026483</td>\n",
       "      <td>0.323087</td>\n",
       "      <td>0.525556</td>\n",
       "      <td>0.400169</td>\n",
       "      <td>0.823913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.015123</td>\n",
       "      <td>0.315405</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.394846</td>\n",
       "      <td>0.824758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.038397</td>\n",
       "      <td>0.322882</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.403501</td>\n",
       "      <td>0.823443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.064076</td>\n",
       "      <td>0.315929</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>0.396187</td>\n",
       "      <td>0.820750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.059248</td>\n",
       "      <td>0.312334</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.391196</td>\n",
       "      <td>0.821846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.031363</td>\n",
       "      <td>0.313066</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.395748</td>\n",
       "      <td>0.823756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.046566</td>\n",
       "      <td>0.316864</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.823537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.040207</td>\n",
       "      <td>0.300518</td>\n",
       "      <td>0.515556</td>\n",
       "      <td>0.379705</td>\n",
       "      <td>0.822879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.038422</td>\n",
       "      <td>0.314888</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>0.395368</td>\n",
       "      <td>0.823944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>0.328209</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.409850</td>\n",
       "      <td>0.823412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.058386</td>\n",
       "      <td>0.322125</td>\n",
       "      <td>0.532222</td>\n",
       "      <td>0.401341</td>\n",
       "      <td>0.823192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.066492</td>\n",
       "      <td>0.330842</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.410624</td>\n",
       "      <td>0.825572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.077358</td>\n",
       "      <td>0.320054</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.398152</td>\n",
       "      <td>0.822848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.080019</td>\n",
       "      <td>0.314379</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.395885</td>\n",
       "      <td>0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.101696</td>\n",
       "      <td>0.307087</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.386139</td>\n",
       "      <td>0.819685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.105894</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>0.400168</td>\n",
       "      <td>0.819247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.092642</td>\n",
       "      <td>0.319868</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.400830</td>\n",
       "      <td>0.821627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.082469</td>\n",
       "      <td>0.313492</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.393035</td>\n",
       "      <td>0.826167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>1.107463</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.399502</td>\n",
       "      <td>0.821251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.121963</td>\n",
       "      <td>0.317385</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>0.820061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.104739</td>\n",
       "      <td>0.323293</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.822065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.150586</td>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.536667</td>\n",
       "      <td>0.401163</td>\n",
       "      <td>0.822597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.126317</td>\n",
       "      <td>0.318821</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>0.397827</td>\n",
       "      <td>0.822910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.112624</td>\n",
       "      <td>0.314997</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>0.396374</td>\n",
       "      <td>0.821658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.101409</td>\n",
       "      <td>0.320979</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.402323</td>\n",
       "      <td>0.823913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.161980</td>\n",
       "      <td>0.321311</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.404124</td>\n",
       "      <td>0.820624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.140600</td>\n",
       "      <td>0.339973</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.420204</td>\n",
       "      <td>0.822879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.117310</td>\n",
       "      <td>0.327563</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.409659</td>\n",
       "      <td>0.822441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.118506</td>\n",
       "      <td>0.327416</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.825604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.105794</td>\n",
       "      <td>0.321476</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.403639</td>\n",
       "      <td>0.823505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.121174</td>\n",
       "      <td>0.325017</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.404532</td>\n",
       "      <td>0.826919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.154151</td>\n",
       "      <td>0.318548</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.396985</td>\n",
       "      <td>0.823693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.134842</td>\n",
       "      <td>0.329939</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.409608</td>\n",
       "      <td>0.823662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.135468</td>\n",
       "      <td>0.328167</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.408557</td>\n",
       "      <td>0.824351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.125487</td>\n",
       "      <td>0.317183</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.401144</td>\n",
       "      <td>0.823850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.132809</td>\n",
       "      <td>0.332208</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.413272</td>\n",
       "      <td>0.823224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.144384</td>\n",
       "      <td>0.335867</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.414146</td>\n",
       "      <td>0.823161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.147408</td>\n",
       "      <td>0.339545</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.418902</td>\n",
       "      <td>0.823067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.152603</td>\n",
       "      <td>0.333562</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.412712</td>\n",
       "      <td>0.822535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>1.140838</td>\n",
       "      <td>0.332650</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.412014</td>\n",
       "      <td>0.826167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.141378</td>\n",
       "      <td>0.326872</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.408180</td>\n",
       "      <td>0.823161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.162573</td>\n",
       "      <td>0.335404</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.823036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.162227</td>\n",
       "      <td>0.339411</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.416165</td>\n",
       "      <td>0.825071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.142309</td>\n",
       "      <td>0.325069</td>\n",
       "      <td>0.524444</td>\n",
       "      <td>0.401361</td>\n",
       "      <td>0.826449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.162874</td>\n",
       "      <td>0.328984</td>\n",
       "      <td>0.532222</td>\n",
       "      <td>0.406621</td>\n",
       "      <td>0.825165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.147786</td>\n",
       "      <td>0.337162</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.419328</td>\n",
       "      <td>0.823819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.184736</td>\n",
       "      <td>0.328028</td>\n",
       "      <td>0.526667</td>\n",
       "      <td>0.404264</td>\n",
       "      <td>0.825197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.180059</td>\n",
       "      <td>0.344657</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.421098</td>\n",
       "      <td>0.820374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.152561</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.408784</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.178608</td>\n",
       "      <td>0.347548</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.423927</td>\n",
       "      <td>0.823004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.167187</td>\n",
       "      <td>0.334708</td>\n",
       "      <td>0.541111</td>\n",
       "      <td>0.413588</td>\n",
       "      <td>0.824664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.203120</td>\n",
       "      <td>0.322965</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.404811</td>\n",
       "      <td>0.821376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.158937</td>\n",
       "      <td>0.334691</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.415508</td>\n",
       "      <td>0.827952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.204924</td>\n",
       "      <td>0.327632</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.411570</td>\n",
       "      <td>0.821439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.169508</td>\n",
       "      <td>0.330399</td>\n",
       "      <td>0.542222</td>\n",
       "      <td>0.410602</td>\n",
       "      <td>0.824821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.193283</td>\n",
       "      <td>0.340644</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.421365</td>\n",
       "      <td>0.821783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.182144</td>\n",
       "      <td>0.335124</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.823098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.206839</td>\n",
       "      <td>0.336857</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>0.412247</td>\n",
       "      <td>0.820687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.186573</td>\n",
       "      <td>0.338367</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.418328</td>\n",
       "      <td>0.821376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.191721</td>\n",
       "      <td>0.334675</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.417399</td>\n",
       "      <td>0.824288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.207983</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.411567</td>\n",
       "      <td>0.823224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.162533</td>\n",
       "      <td>0.335124</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.825792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.203515</td>\n",
       "      <td>0.325050</td>\n",
       "      <td>0.537778</td>\n",
       "      <td>0.405190</td>\n",
       "      <td>0.823850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.160986</td>\n",
       "      <td>0.334014</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.414346</td>\n",
       "      <td>0.827639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.194063</td>\n",
       "      <td>0.352192</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.430424</td>\n",
       "      <td>0.826731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.178442</td>\n",
       "      <td>0.342380</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.828422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.183116</td>\n",
       "      <td>0.335146</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.415858</td>\n",
       "      <td>0.830113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.199897</td>\n",
       "      <td>0.336756</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.416773</td>\n",
       "      <td>0.826512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.189629</td>\n",
       "      <td>0.340720</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.419795</td>\n",
       "      <td>0.827702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.186535</td>\n",
       "      <td>0.345095</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.422098</td>\n",
       "      <td>0.829142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.252872</td>\n",
       "      <td>0.349823</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.427646</td>\n",
       "      <td>0.822848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.215938</td>\n",
       "      <td>0.335602</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.416209</td>\n",
       "      <td>0.826668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.193198</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.421941</td>\n",
       "      <td>0.828297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.184158</td>\n",
       "      <td>0.341904</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.420693</td>\n",
       "      <td>0.828704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.217874</td>\n",
       "      <td>0.340736</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.419479</td>\n",
       "      <td>0.826981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.261694</td>\n",
       "      <td>0.332213</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.413909</td>\n",
       "      <td>0.823255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.198181</td>\n",
       "      <td>0.335575</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.418098</td>\n",
       "      <td>0.823662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.166351</td>\n",
       "      <td>0.337856</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.419545</td>\n",
       "      <td>0.829737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.178015</td>\n",
       "      <td>0.359857</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.437473</td>\n",
       "      <td>0.829925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.200423</td>\n",
       "      <td>0.351541</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.431271</td>\n",
       "      <td>0.830959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.182358</td>\n",
       "      <td>0.340470</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.419932</td>\n",
       "      <td>0.832462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.193356</td>\n",
       "      <td>0.339006</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.420431</td>\n",
       "      <td>0.827670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.197462</td>\n",
       "      <td>0.340893</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.421231</td>\n",
       "      <td>0.828829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.186707</td>\n",
       "      <td>0.331349</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.415423</td>\n",
       "      <td>0.826574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.235926</td>\n",
       "      <td>0.333555</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.417152</td>\n",
       "      <td>0.819059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.205664</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.413936</td>\n",
       "      <td>0.826293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.199932</td>\n",
       "      <td>0.347978</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.427592</td>\n",
       "      <td>0.830395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.209767</td>\n",
       "      <td>0.322977</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.408180</td>\n",
       "      <td>0.824633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.230454</td>\n",
       "      <td>0.325519</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.406185</td>\n",
       "      <td>0.822660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.223801</td>\n",
       "      <td>0.329010</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.407611</td>\n",
       "      <td>0.825510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.201441</td>\n",
       "      <td>0.352983</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.428634</td>\n",
       "      <td>0.825760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.237287</td>\n",
       "      <td>0.353641</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.433849</td>\n",
       "      <td>0.824758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.223430</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.416354</td>\n",
       "      <td>0.825572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.220490</td>\n",
       "      <td>0.334473</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.414056</td>\n",
       "      <td>0.827796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.210658</td>\n",
       "      <td>0.340644</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.421365</td>\n",
       "      <td>0.827545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.231643</td>\n",
       "      <td>0.346695</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.424634</td>\n",
       "      <td>0.823286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.241994</td>\n",
       "      <td>0.343056</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.823224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.232428</td>\n",
       "      <td>0.342975</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.423469</td>\n",
       "      <td>0.824695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.212026</td>\n",
       "      <td>0.339053</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.419177</td>\n",
       "      <td>0.827420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.239570</td>\n",
       "      <td>0.351994</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.824852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.233669</td>\n",
       "      <td>0.350173</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.431557</td>\n",
       "      <td>0.825228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.204559</td>\n",
       "      <td>0.343643</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.424628</td>\n",
       "      <td>0.830489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.214916</td>\n",
       "      <td>0.340555</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.423223</td>\n",
       "      <td>0.826167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.214712</td>\n",
       "      <td>0.346897</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.428085</td>\n",
       "      <td>0.827608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.229332</td>\n",
       "      <td>0.348611</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.429060</td>\n",
       "      <td>0.827138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.243093</td>\n",
       "      <td>0.359630</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.438665</td>\n",
       "      <td>0.827389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.235597</td>\n",
       "      <td>0.360347</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.436459</td>\n",
       "      <td>0.827013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.245857</td>\n",
       "      <td>0.359972</td>\n",
       "      <td>0.565556</td>\n",
       "      <td>0.439931</td>\n",
       "      <td>0.826574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.220272</td>\n",
       "      <td>0.352361</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.431220</td>\n",
       "      <td>0.831178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.233688</td>\n",
       "      <td>0.365274</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.830395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.231813</td>\n",
       "      <td>0.357243</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>0.828986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.245602</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.433621</td>\n",
       "      <td>0.826981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.253342</td>\n",
       "      <td>0.347434</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.427839</td>\n",
       "      <td>0.825197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.236929</td>\n",
       "      <td>0.352152</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.430729</td>\n",
       "      <td>0.830489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.251633</td>\n",
       "      <td>0.364493</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.441228</td>\n",
       "      <td>0.829236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.236875</td>\n",
       "      <td>0.344804</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.425839</td>\n",
       "      <td>0.829581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.234991</td>\n",
       "      <td>0.354430</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.434109</td>\n",
       "      <td>0.831554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.240661</td>\n",
       "      <td>0.349306</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.429915</td>\n",
       "      <td>0.827984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.245036</td>\n",
       "      <td>0.343131</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.424884</td>\n",
       "      <td>0.828704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.239638</td>\n",
       "      <td>0.359320</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.438771</td>\n",
       "      <td>0.831209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.248671</td>\n",
       "      <td>0.356794</td>\n",
       "      <td>0.568889</td>\n",
       "      <td>0.438544</td>\n",
       "      <td>0.828297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.299524</td>\n",
       "      <td>0.350416</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.431741</td>\n",
       "      <td>0.823130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.272763</td>\n",
       "      <td>0.350171</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.433827</td>\n",
       "      <td>0.826136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.267246</td>\n",
       "      <td>0.360539</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.440017</td>\n",
       "      <td>0.826324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.239394</td>\n",
       "      <td>0.357971</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.830050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.256575</td>\n",
       "      <td>0.353857</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.432339</td>\n",
       "      <td>0.827921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.258652</td>\n",
       "      <td>0.351447</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.429866</td>\n",
       "      <td>0.828140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.254009</td>\n",
       "      <td>0.348936</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.425974</td>\n",
       "      <td>0.830708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.281682</td>\n",
       "      <td>0.349542</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.427771</td>\n",
       "      <td>0.823098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.256910</td>\n",
       "      <td>0.354270</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.433319</td>\n",
       "      <td>0.827483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.311865</td>\n",
       "      <td>0.356174</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.433724</td>\n",
       "      <td>0.824476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>0.342287</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.422619</td>\n",
       "      <td>0.821345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.231328</td>\n",
       "      <td>0.340690</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.420426</td>\n",
       "      <td>0.831992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.237518</td>\n",
       "      <td>0.350595</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.430228</td>\n",
       "      <td>0.827232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.236029</td>\n",
       "      <td>0.340925</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.828860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.268534</td>\n",
       "      <td>0.346528</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.426496</td>\n",
       "      <td>0.828109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.303293</td>\n",
       "      <td>0.351026</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.428880</td>\n",
       "      <td>0.823787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.240742</td>\n",
       "      <td>0.362573</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.437390</td>\n",
       "      <td>0.831867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.254163</td>\n",
       "      <td>0.360539</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.440017</td>\n",
       "      <td>0.828391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.265408</td>\n",
       "      <td>0.363702</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.442023</td>\n",
       "      <td>0.827764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.266698</td>\n",
       "      <td>0.351557</td>\n",
       "      <td>0.564444</td>\n",
       "      <td>0.433262</td>\n",
       "      <td>0.828046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.266072</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.283130</td>\n",
       "      <td>0.352442</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>0.825666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.259323</td>\n",
       "      <td>0.360262</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.435356</td>\n",
       "      <td>0.828766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.218578</td>\n",
       "      <td>0.350136</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>0.434122</td>\n",
       "      <td>0.828391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.279697</td>\n",
       "      <td>0.357597</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.437149</td>\n",
       "      <td>0.822222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.249080</td>\n",
       "      <td>0.350069</td>\n",
       "      <td>0.565556</td>\n",
       "      <td>0.432455</td>\n",
       "      <td>0.826386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.245579</td>\n",
       "      <td>0.357963</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.435048</td>\n",
       "      <td>0.830489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.256723</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.430192</td>\n",
       "      <td>0.827483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.255103</td>\n",
       "      <td>0.351182</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.431993</td>\n",
       "      <td>0.827357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.251197</td>\n",
       "      <td>0.346841</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.428693</td>\n",
       "      <td>0.829549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.260711</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.426803</td>\n",
       "      <td>0.827858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.270266</td>\n",
       "      <td>0.350140</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.429553</td>\n",
       "      <td>0.826418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.253586</td>\n",
       "      <td>0.342069</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.422128</td>\n",
       "      <td>0.828923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.297772</td>\n",
       "      <td>0.330201</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.411715</td>\n",
       "      <td>0.824226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.277452</td>\n",
       "      <td>0.349466</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.827858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.269707</td>\n",
       "      <td>0.346741</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.426985</td>\n",
       "      <td>0.827389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.259452</td>\n",
       "      <td>0.352523</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.429996</td>\n",
       "      <td>0.829455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.256473</td>\n",
       "      <td>0.347886</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.428510</td>\n",
       "      <td>0.829080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.254708</td>\n",
       "      <td>0.359175</td>\n",
       "      <td>0.561111</td>\n",
       "      <td>0.437988</td>\n",
       "      <td>0.831554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.258482</td>\n",
       "      <td>0.353693</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.431542</td>\n",
       "      <td>0.830270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.278774</td>\n",
       "      <td>0.354342</td>\n",
       "      <td>0.562222</td>\n",
       "      <td>0.434708</td>\n",
       "      <td>0.829549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.256588</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.440917</td>\n",
       "      <td>0.832744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.261224</td>\n",
       "      <td>0.365537</td>\n",
       "      <td>0.563333</td>\n",
       "      <td>0.443376</td>\n",
       "      <td>0.832618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.263058</td>\n",
       "      <td>0.353189</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.433176</td>\n",
       "      <td>0.832055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.286707</td>\n",
       "      <td>0.356264</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.431390</td>\n",
       "      <td>0.830426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.295918</td>\n",
       "      <td>0.341702</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.419880</td>\n",
       "      <td>0.827232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.254739</td>\n",
       "      <td>0.357654</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.435161</td>\n",
       "      <td>0.833934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.281169</td>\n",
       "      <td>0.349129</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.429122</td>\n",
       "      <td>0.828422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.278024</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.424034</td>\n",
       "      <td>0.831303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.236075</td>\n",
       "      <td>0.350035</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.428140</td>\n",
       "      <td>0.834873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.262688</td>\n",
       "      <td>0.332427</td>\n",
       "      <td>0.543333</td>\n",
       "      <td>0.412484</td>\n",
       "      <td>0.830364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.288443</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.432596</td>\n",
       "      <td>0.828171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.282831</td>\n",
       "      <td>0.331981</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.412778</td>\n",
       "      <td>0.826981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.319305</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.428758</td>\n",
       "      <td>0.825917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.302343</td>\n",
       "      <td>0.355508</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.824602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.283590</td>\n",
       "      <td>0.335362</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.416982</td>\n",
       "      <td>0.830458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.309376</td>\n",
       "      <td>0.346853</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.425751</td>\n",
       "      <td>0.827075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.276041</td>\n",
       "      <td>0.353780</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>0.833777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.278574</td>\n",
       "      <td>0.349372</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.429306</td>\n",
       "      <td>0.833558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.276603</td>\n",
       "      <td>0.356379</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.434216</td>\n",
       "      <td>0.833996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.273771</td>\n",
       "      <td>0.355460</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.432855</td>\n",
       "      <td>0.833589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.287146</td>\n",
       "      <td>0.353770</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.432945</td>\n",
       "      <td>0.829205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.283650</td>\n",
       "      <td>0.356787</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.435197</td>\n",
       "      <td>0.832086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.278744</td>\n",
       "      <td>0.353442</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.431356</td>\n",
       "      <td>0.830019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.290699</td>\n",
       "      <td>0.353770</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.432945</td>\n",
       "      <td>0.832681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.281232</td>\n",
       "      <td>0.354359</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.432713</td>\n",
       "      <td>0.831648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.280161</td>\n",
       "      <td>0.354314</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.433016</td>\n",
       "      <td>0.830301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.303281</td>\n",
       "      <td>0.348401</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.828359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.285155</td>\n",
       "      <td>0.349096</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.429427</td>\n",
       "      <td>0.830050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.286618</td>\n",
       "      <td>0.348070</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.829142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.291413</td>\n",
       "      <td>0.352401</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.430915</td>\n",
       "      <td>0.829706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.294419</td>\n",
       "      <td>0.343232</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.423339</td>\n",
       "      <td>0.827764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.285995</td>\n",
       "      <td>0.346953</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.427474</td>\n",
       "      <td>0.830833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.278575</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.428633</td>\n",
       "      <td>0.830896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.274264</td>\n",
       "      <td>0.342541</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.422487</td>\n",
       "      <td>0.830739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.284292</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.424946</td>\n",
       "      <td>0.828516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.310589</td>\n",
       "      <td>0.337178</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.418703</td>\n",
       "      <td>0.826574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.295157</td>\n",
       "      <td>0.353746</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.429196</td>\n",
       "      <td>0.830645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.271640</td>\n",
       "      <td>0.350282</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.428325</td>\n",
       "      <td>0.833965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.310828</td>\n",
       "      <td>0.345164</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.424476</td>\n",
       "      <td>0.825416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.309774</td>\n",
       "      <td>0.332194</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.411342</td>\n",
       "      <td>0.828328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.278247</td>\n",
       "      <td>0.360549</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.436953</td>\n",
       "      <td>0.832493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.297897</td>\n",
       "      <td>0.344899</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.424605</td>\n",
       "      <td>0.829424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.291926</td>\n",
       "      <td>0.349195</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.428510</td>\n",
       "      <td>0.831272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.294590</td>\n",
       "      <td>0.338545</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.420076</td>\n",
       "      <td>0.831272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.299373</td>\n",
       "      <td>0.343901</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>0.831178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.296236</td>\n",
       "      <td>0.352152</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.430729</td>\n",
       "      <td>0.831178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.303774</td>\n",
       "      <td>0.357654</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.435161</td>\n",
       "      <td>0.829956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.309105</td>\n",
       "      <td>0.349162</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.428816</td>\n",
       "      <td>0.831491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.294285</td>\n",
       "      <td>0.347705</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.427716</td>\n",
       "      <td>0.831522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.309138</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.423908</td>\n",
       "      <td>0.828171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.295665</td>\n",
       "      <td>0.339065</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.418862</td>\n",
       "      <td>0.832462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.292722</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.417722</td>\n",
       "      <td>0.829299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.292612</td>\n",
       "      <td>0.336277</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.417369</td>\n",
       "      <td>0.830865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.288922</td>\n",
       "      <td>0.344875</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.424915</td>\n",
       "      <td>0.832618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.322572</td>\n",
       "      <td>0.341346</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.421902</td>\n",
       "      <td>0.825979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.297862</td>\n",
       "      <td>0.355021</td>\n",
       "      <td>0.557778</td>\n",
       "      <td>0.433881</td>\n",
       "      <td>0.828391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.303216</td>\n",
       "      <td>0.349296</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.427586</td>\n",
       "      <td>0.828892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.306488</td>\n",
       "      <td>0.349474</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.428387</td>\n",
       "      <td>0.829956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.299223</td>\n",
       "      <td>0.352436</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.831585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.298981</td>\n",
       "      <td>0.356017</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.432927</td>\n",
       "      <td>0.830990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.304115</td>\n",
       "      <td>0.350603</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.427891</td>\n",
       "      <td>0.830458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.304644</td>\n",
       "      <td>0.346780</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.423692</td>\n",
       "      <td>0.830614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.300116</td>\n",
       "      <td>0.362582</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.438789</td>\n",
       "      <td>0.831741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.301077</td>\n",
       "      <td>0.361131</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.437034</td>\n",
       "      <td>0.830364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.305748</td>\n",
       "      <td>0.345379</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.424968</td>\n",
       "      <td>0.829675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.314173</td>\n",
       "      <td>0.341649</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.420828</td>\n",
       "      <td>0.828015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.295949</td>\n",
       "      <td>0.346287</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.426314</td>\n",
       "      <td>0.831554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.290538</td>\n",
       "      <td>0.351161</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.429987</td>\n",
       "      <td>0.832399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.309439</td>\n",
       "      <td>0.353109</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.429752</td>\n",
       "      <td>0.830050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.329056</td>\n",
       "      <td>0.347242</td>\n",
       "      <td>0.545556</td>\n",
       "      <td>0.424373</td>\n",
       "      <td>0.827545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.286068</td>\n",
       "      <td>0.354494</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.431798</td>\n",
       "      <td>0.833151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.292562</td>\n",
       "      <td>0.354908</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.432784</td>\n",
       "      <td>0.830739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.292620</td>\n",
       "      <td>0.339506</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.419847</td>\n",
       "      <td>0.831303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>1.291455</td>\n",
       "      <td>0.344684</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.424113</td>\n",
       "      <td>0.831992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.284848</td>\n",
       "      <td>0.352401</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.430915</td>\n",
       "      <td>0.832712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.294754</td>\n",
       "      <td>0.349083</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.427092</td>\n",
       "      <td>0.830050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.294513</td>\n",
       "      <td>0.349229</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.428203</td>\n",
       "      <td>0.831053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.292086</td>\n",
       "      <td>0.357963</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.435048</td>\n",
       "      <td>0.831616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.297988</td>\n",
       "      <td>0.346181</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.830489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.296231</td>\n",
       "      <td>0.338832</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.418684</td>\n",
       "      <td>0.831021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.292787</td>\n",
       "      <td>0.341649</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.420828</td>\n",
       "      <td>0.831460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.289097</td>\n",
       "      <td>0.350318</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.428016</td>\n",
       "      <td>0.831835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.290477</td>\n",
       "      <td>0.358735</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>0.435618</td>\n",
       "      <td>0.831679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.295403</td>\n",
       "      <td>0.355859</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.432126</td>\n",
       "      <td>0.831178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.294798</td>\n",
       "      <td>0.350989</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.429188</td>\n",
       "      <td>0.831053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.294359</td>\n",
       "      <td>0.351983</td>\n",
       "      <td>0.552222</td>\n",
       "      <td>0.429931</td>\n",
       "      <td>0.831084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.295671</td>\n",
       "      <td>0.349858</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>0.427336</td>\n",
       "      <td>0.830959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.295978</td>\n",
       "      <td>0.348903</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.426286</td>\n",
       "      <td>0.831053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.293753</td>\n",
       "      <td>0.348101</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.426357</td>\n",
       "      <td>0.831898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.293327</td>\n",
       "      <td>0.344708</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.423801</td>\n",
       "      <td>0.831710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.293283</td>\n",
       "      <td>0.345645</td>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.424839</td>\n",
       "      <td>0.831867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.293508</td>\n",
       "      <td>0.347125</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.425623</td>\n",
       "      <td>0.831867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-23\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-23/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-23/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-23/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-23/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-46\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-46/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-46/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-46/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-46/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-69\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-69/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-69/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-69/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-69/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-92\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-92/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-92/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-92/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-92/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-115\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-115/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-115/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-115/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-115/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-138\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-138/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-138/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-138/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-138/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-161\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-161/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-161/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-161/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-161/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-184\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-184/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-184/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-184/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-184/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-207\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-207/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-207/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-207/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-207/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-230\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-230/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-230/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-230/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-230/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-253\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-253/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-253/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-253/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-253/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-276\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-276/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-276/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-276/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-276/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-299\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-299/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-299/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-299/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-299/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-322\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-322/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-322/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-322/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-322/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-345\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-345/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-345/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-345/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-345/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-368\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-368/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-368/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-368/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-368/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-391\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-391/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-391/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-391/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-391/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-414\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-414/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-414/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-414/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-414/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-437\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-437/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-437/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-437/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-437/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-460\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-460/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-460/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-460/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-460/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-483\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-483/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-483/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-483/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-483/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-506\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-506/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-506/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-506/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-506/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-529\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-529/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-529/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-529/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-529/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-552\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-552/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-552/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-552/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-552/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-575\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-575/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-575/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-575/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-575/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-598\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-598/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-598/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-598/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-598/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-621\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-621/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-621/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-621/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-621/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-644\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-644/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-644/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-644/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-644/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-667\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-667/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-667/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-667/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-667/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-690\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-690/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-690/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-690/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-690/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-713\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-713/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-713/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-713/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-713/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-736\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-736/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-736/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-736/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-736/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-759\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-759/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-759/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-759/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-759/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-782\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-782/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-782/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-805\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-805/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-805/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-805/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-805/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-828\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-828/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-828/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-828/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-828/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-851\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-851/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-851/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-851/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-851/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-874\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-874/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-874/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-874/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-874/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-897\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-897/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-897/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-897/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-897/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-920\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-920/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-920/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-920/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-920/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-943\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-943/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-943/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-943/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-943/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-966\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-966/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-966/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-966/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-966/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-989\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-989/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-989/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-989/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-989/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1012\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1012/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1012/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1012/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1012/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1035\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1035/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1035/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1035/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1035/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1058\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1058/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1058/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1058/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1058/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1081\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1081/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1081/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1081/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1081/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1104\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1104/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1104/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1104/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1104/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1127\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1127/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1127/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1127/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1127/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1150\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1150/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1150/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1150/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1150/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1173\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1173/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1173/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1173/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1173/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1196\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1196/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1196/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1196/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1196/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1219\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1219/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1219/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1219/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1219/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1242\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1242/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1242/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1242/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1242/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1265\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1265/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1265/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1265/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1265/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1288\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1288/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1288/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1288/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1288/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1311\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1311/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1311/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1311/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1311/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1334\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1334/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1334/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1334/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1334/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1357\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1357/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1357/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1357/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1357/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1380\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1380/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1380/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1380/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1380/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1403\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1403/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1403/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1403/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1403/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1426\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1426/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1426/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1426/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1426/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1449\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1449/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1449/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1449/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1449/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1472\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1472/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1472/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1472/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1472/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1495\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1495/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1495/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1495/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1495/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1518\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1518/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1518/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1518/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1518/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1541\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1541/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1541/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1541/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1541/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1564\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1564/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1564/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1587\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1587/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1587/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1587/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1587/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1610\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1610/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1610/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1610/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1610/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1633\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1633/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1633/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1633/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1633/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1656\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1656/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1656/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1656/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1656/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1679\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1679/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1679/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1679/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1679/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1702\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1702/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1702/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1702/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1702/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1725\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1725/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1725/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1725/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1725/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1748\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1748/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1748/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1748/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1748/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1771\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1771/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1771/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1771/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1771/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1794\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1794/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1794/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1794/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1794/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1817\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1817/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1817/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1817/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1817/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1840\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1840/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1840/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1840/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1840/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1863\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1863/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1863/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1863/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1863/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1886\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1886/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1886/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1886/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1886/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1909\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1909/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1909/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1909/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1909/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1932\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1932/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1932/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1932/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1932/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1955\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1955/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1955/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1955/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1955/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-1978\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-1978/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-1978/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-1978/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-1978/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2001\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2001/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2001/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2001/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2001/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2024\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2024/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2024/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2024/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2024/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2047\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2047/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2047/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2047/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2047/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2070\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2070/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2070/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2070/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2070/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2093\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2093/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2093/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2093/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2093/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2116\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2116/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2116/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2116/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2116/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2139\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2139/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2139/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2139/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2139/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2162\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2162/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2162/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2162/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2162/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2185\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2185/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2185/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2185/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2185/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2208\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2208/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2208/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2208/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2208/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2231\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2231/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2231/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2231/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2231/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2254\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2254/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2254/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2254/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2254/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2277\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2277/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2277/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2277/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2277/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2300\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2300/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2300/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2300/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2300/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2323\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2323/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2323/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2323/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2323/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2346\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2346/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2346/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2369\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2369/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2369/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2369/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2369/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2392\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2392/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2392/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2392/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2392/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2415\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2415/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2415/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2415/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2415/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2438\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2438/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2438/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2438/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2438/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2461\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2461/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2461/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2461/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2461/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2484\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2484/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2484/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2484/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2484/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2507\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2507/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2507/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2507/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2507/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2530\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2530/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2530/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2530/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2530/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2553\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2553/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2553/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2553/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2553/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2576\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2576/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2576/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2576/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2576/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2599\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2599/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2599/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2599/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2599/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2622\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2622/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2622/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2622/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2622/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2645\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2645/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2645/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2645/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2645/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2668\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2668/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2668/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2668/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2668/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2691\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2691/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2691/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2691/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2691/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2714\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2714/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2714/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2714/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2714/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2737\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2737/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2737/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2737/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2737/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2760\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2760/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2760/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2760/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2760/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2783\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2783/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2783/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2783/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2783/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2806\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2806/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2806/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2806/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2806/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2829\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2829/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2829/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2829/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2829/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2852\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2852/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2852/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2852/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2852/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2875\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2875/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2875/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2875/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2875/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2898\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2898/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2898/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2898/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2898/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2921\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2921/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2921/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2921/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2921/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2944\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2944/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2944/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2944/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2944/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2967\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2967/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2967/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2967/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2967/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-2990\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-2990/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-2990/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-2990/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-2990/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3013\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3013/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3013/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3013/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3013/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3036\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3036/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3036/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3036/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3036/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3059\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3059/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3059/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3059/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3059/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3082\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3082/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3082/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3082/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3082/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3105\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3105/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3105/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3105/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3105/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3128\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3128/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3128/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3151\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3151/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3151/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3151/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3151/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3174\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3174/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3174/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3174/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3174/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3197\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3197/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3197/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3197/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3197/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3220\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3220/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3220/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3220/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3220/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3243\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3243/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3243/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3243/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3243/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3266\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3266/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3266/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3266/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3266/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3289\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3289/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3289/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3289/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3289/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3312\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3312/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3312/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3312/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3312/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3335\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3335/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3335/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3335/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3335/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3358\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3358/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3358/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3358/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3358/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3381\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3381/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3381/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3381/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3381/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3404\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3404/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3404/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3404/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3404/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3427\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3427/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3427/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3427/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3427/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3450\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3450/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3450/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3450/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3450/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3473\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3473/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3473/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3473/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3473/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3496\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3496/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3496/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3496/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3496/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3519\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3519/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3519/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3519/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3519/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3542\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3542/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3542/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3542/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3542/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3565\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3565/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3565/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3565/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3565/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3588\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3588/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3588/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3588/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3588/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3611\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3611/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3611/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3611/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3611/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3634\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3634/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3634/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3634/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3634/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3657\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3657/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3657/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3657/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3657/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3680\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3680/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3680/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3680/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3680/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3703\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3703/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3703/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3703/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3703/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3726\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3726/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3726/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3726/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3726/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3749\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3749/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3749/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3749/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3749/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3772\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3772/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3772/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3772/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3772/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3795\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3795/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3795/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3795/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3795/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3818\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3818/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3818/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3818/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3818/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3841\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3841/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3841/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3841/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3841/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3864\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3864/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3864/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3864/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3864/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3887\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3887/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3887/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3887/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3887/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3910\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3910/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3910/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3933\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3933/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3933/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3933/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3933/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3956\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3956/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3956/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3956/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3956/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-3979\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-3979/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-3979/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-3979/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-3979/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4002\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4002/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4002/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4002/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4002/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4025\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4025/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4025/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4025/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4025/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4048\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4048/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4048/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4048/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4048/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4071\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4071/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4071/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4071/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4071/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4094\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4094/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4094/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4094/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4094/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4117\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4117/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4117/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4117/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4117/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4140\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4140/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4140/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4140/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4140/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4163\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4163/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4163/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4163/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4163/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4186\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4186/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4186/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4186/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4186/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4209\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4209/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4209/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4209/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4209/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4232\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4232/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4232/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4232/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4232/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4255\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4255/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4255/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4255/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4255/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4278\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4278/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4278/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4278/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4278/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4301\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4301/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4301/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4301/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4301/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4324\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4324/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4324/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4324/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4324/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4347\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4347/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4347/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4347/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4347/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4370\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4370/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4370/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4370/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4370/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4393\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4393/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4393/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4393/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4393/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4416\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4416/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4416/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4416/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4416/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4439\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4439/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4439/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4439/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4439/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4462\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4462/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4462/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4462/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4462/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4485\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4485/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4485/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4485/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4485/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4508\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4508/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4508/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4508/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4508/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4531\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4531/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4531/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4531/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4531/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4554\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4554/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4554/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4554/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4554/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4577\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4577/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4577/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4577/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4577/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4600\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4600/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4600/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4600/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4600/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4623\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4623/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4623/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4623/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4623/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4646\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4646/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4646/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4646/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4646/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4669\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4669/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4669/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4669/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4669/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4692\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4692/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4692/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4715\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4715/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4715/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4715/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4715/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4738\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4738/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4738/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4738/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4738/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4761\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4761/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4761/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4761/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4761/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4784\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4784/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4784/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4784/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4784/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4807\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4807/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4807/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4807/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4807/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4830\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4830/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4830/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4830/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4830/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4853\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4853/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4853/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4853/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4853/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4876\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4876/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4876/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4876/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4876/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4899\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4899/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4899/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4899/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4899/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4922\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4922/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4922/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4922/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4922/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4945\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4945/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4945/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4945/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4945/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4968\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4968/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4968/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4968/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4968/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-4991\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-4991/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-4991/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-4991/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-4991/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5014\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5014/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5014/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5014/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5014/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5037\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5037/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5037/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5037/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5037/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5060\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5060/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5060/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5060/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5060/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5083\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5083/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5083/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5083/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5083/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5106\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5106/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5106/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5106/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5106/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5129\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5129/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5129/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5129/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5129/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5152\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5152/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5152/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5152/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5152/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5175\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5175/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5175/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5175/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5175/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5198\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5198/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5198/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5198/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5198/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5221\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5221/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5221/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5221/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5221/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5244\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5244/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5244/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5244/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5244/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5267\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5267/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5267/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5267/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5267/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5290\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5290/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5290/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5290/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5290/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5313\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5313/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5313/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5313/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5313/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5336\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5336/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5336/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5336/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5336/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5359\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5359/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5359/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5359/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5359/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5382\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5382/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5382/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5382/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5382/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5405\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5405/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5405/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5405/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5405/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5428\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5428/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5428/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5428/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5428/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5451\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5451/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5451/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5451/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5451/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5474\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5474/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5474/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5497\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5497/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5497/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5497/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5497/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5520\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5520/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5520/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5520/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5520/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5543\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5543/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5543/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5543/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5543/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5566\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5566/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5566/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5566/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5566/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5589\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5589/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5589/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5589/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5589/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5612\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5612/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5612/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5612/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5612/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5635\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5635/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5635/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5635/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5635/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5658\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5658/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5658/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5658/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5658/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5681\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5681/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5681/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5681/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5681/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5704\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5704/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5704/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5704/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5704/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5727\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5727/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5727/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5727/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5727/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5750\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5750/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5750/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5750/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5750/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5773\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5773/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5773/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5773/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5773/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5796\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5796/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5796/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5796/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5796/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5819\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5819/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5819/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5819/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5819/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5842\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5842/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5842/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5842/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5842/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5865\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5865/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5865/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5865/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5865/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5888\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5888/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5888/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5888/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5888/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5911\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5911/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5911/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5911/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5911/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5934\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5934/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5934/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5934/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5934/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5957\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5957/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5957/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5957/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5957/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-5980\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-5980/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-5980/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-5980/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-5980/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6003\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6003/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6003/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6003/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6003/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6026\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6026/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6026/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6026/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6026/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6049\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6049/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6049/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6049/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6049/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6072\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6072/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6072/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6072/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6072/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6095\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6095/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6095/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6095/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6095/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6118\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6118/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6118/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6118/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6118/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6141\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6141/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6141/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6141/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6141/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6164\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6164/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6164/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6164/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6164/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6187\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6187/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6187/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6187/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6187/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6210\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6210/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6210/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6210/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6210/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6233\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6233/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6233/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6233/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6233/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6256\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6256/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6256/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6279\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6279/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6279/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6279/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6279/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6302\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6302/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6302/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6302/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6302/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6325\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6325/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6325/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6325/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6325/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6348\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6348/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6348/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6348/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6348/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6371\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6371/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6371/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6371/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6371/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6394\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6394/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6394/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6394/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6394/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6417\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6417/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6417/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6417/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6417/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6440\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6440/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6440/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6440/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6440/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6463\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6463/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6463/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6463/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6463/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6486\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6486/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6486/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6486/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6486/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6509\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6509/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6509/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6509/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6509/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6532\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6532/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6532/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6532/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6532/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6555\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6555/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6555/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6555/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6555/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6578\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6578/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6578/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6578/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6578/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6601\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6601/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6601/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6601/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6601/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6624\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6624/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6624/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6624/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6624/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6647\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6647/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6647/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6647/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6647/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6670\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6670/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6670/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6670/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6670/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6693\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6693/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6693/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6693/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6693/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6716\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6716/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6716/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6716/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6716/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6739\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6739/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6739/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6739/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6739/special_tokens_map.json\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6762\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6762/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6762/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6762/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6762/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6785\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6785/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6785/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6785/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6785/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6808\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6808/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6808/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6808/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6808/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6831\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6831/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6831/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6831/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6831/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6854\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6854/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6854/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6854/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6854/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6877\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6877/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6877/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6877/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6877/special_tokens_map.json\n",
      "/grupoa/config/miniconda3/envs/fastai/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, tags. If tokens, tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 127\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to clinico-finetuned-augmented1/checkpoint-6900\n",
      "Configuration saved in clinico-finetuned-augmented1/checkpoint-6900/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/checkpoint-6900/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/checkpoint-6900/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/checkpoint-6900/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from clinico-finetuned-augmented1/checkpoint-184 (score: 0.6775755882263184).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6900, training_loss=0.038896890805251355, metrics={'train_runtime': 6929.7647, 'train_samples_per_second': 123.381, 'train_steps_per_second': 0.996, 'total_flos': 1.1173263842304e+17, 'train_loss': 0.038896890805251355, 'epoch': 300.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"clinico-finetuned-augmented1\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dab37a4b-6ba8-40c2-b570-a57d653ba06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to clinico-finetuned-augmented1\n",
      "Configuration saved in clinico-finetuned-augmented1/config.json\n",
      "Model weights saved in clinico-finetuned-augmented1/pytorch_model.bin\n",
      "tokenizer config file saved in clinico-finetuned-augmented1/tokenizer_config.json\n",
      "Special tokens file saved in clinico-finetuned-augmented1/special_tokens_map.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.025615453720092773,
       "initial": 32768,
       "n": 32768,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file pytorch_model.bin",
       "rate": null,
       "total": 267003941,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5761af77f4c844a086b78024951acd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.028720855712890625,
       "initial": 32768,
       "n": 32768,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Upload file runs/Mar17_10-14-57_minion/events.out.tfevents.1679044506.minion.151280.0",
       "rate": null,
       "total": 148618,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccb533244b549baa8dfba0b1c652797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file runs/Mar17_10-14-57_minion/events.out.tfevents.1679044506.minion.151280.0:  22%|##2       | 32.0k/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/joheras/clinico-finetuned-augmented1\n",
      "   d31130a..6de2de2  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'metrics': [{'name': 'Precision', 'type': 'precision', 'value': 0.34712482468443195}, {'name': 'Recall', 'type': 'recall', 'value': 0.55}, {'name': 'F1', 'type': 'f1', 'value': 0.42562338779019776}, {'name': 'Accuracy', 'type': 'accuracy', 'value': 0.8318667209469828}]}\n",
      "To https://huggingface.co/joheras/clinico-finetuned-augmented1\n",
      "   6de2de2..e33d632  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/joheras/clinico-finetuned-augmented1/commit/6de2de2833a7c5011e1e068f8003fb307082befe'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58d5781-2f12-4b75-8de4-c998d6e6cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf clinico-finetuned-augmented1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d4449-dfa6-45e3-a0a6-e32f2a40c9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
